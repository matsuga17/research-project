---
name: strategic-organizational-research-hub
description: Comprehensive data collection, analysis, and theory-building system specialized for empirical research in business strategy and organizational strategy. This skill activates when users need to design quantitative studies, collect firm-level and industry-level data, construct theoretical frameworks, conduct statistical analysis, and produce publication-ready research in strategic management, organizational theory, competitive dynamics, and related fields.
---

# Strategic & Organizational Research Hub

A comprehensive skill for managing the entire research lifecycle in business strategy and organizational strategy empirical research—from theoretical framework development to data collection, statistical analysis, and academic paper writing.

## When to Use This Skill

This skill should be used when:
- Planning empirical research in strategic management or organizational studies
- Designing quantitative studies on competitive strategy, business models, organizational design, or strategic decision-making
- Searching for firm-level, industry-level, or market-level data
- Constructing theoretical frameworks for strategy research
- Conducting statistical analysis (regression, panel data, event studies, etc.)
- Writing academic papers for strategy/organization journals (SMJ, AMJ, OS, etc.)
- Reviewing literature in strategy and organization fields
- Preparing research proposals for strategy research
- Replicating or extending existing strategy research

## Core Research Domains Covered

### Business Strategy Research Areas
1. **Competitive Strategy**: Porter's five forces, competitive dynamics, strategic positioning, competitive advantage
2. **Corporate Strategy**: Diversification, vertical integration, M&A, portfolio management, corporate restructuring
3. **International Strategy**: Global expansion, entry modes, multinational strategy, cross-border M&A
4. **Innovation Strategy**: R&D investment, innovation ecosystems, disruptive innovation, open innovation
5. **Business Models**: Platform strategy, digital transformation, business model innovation, value creation/capture
6. **Strategic Alliances**: Joint ventures, partnerships, alliance portfolios, network strategy
7. **ESG & Sustainability**: Corporate social responsibility, environmental strategy, sustainable competitive advantage

### Organizational Strategy Research Areas
1. **Organizational Design**: Structure, hierarchy, decentralization, organizational complexity
2. **Organizational Learning**: Knowledge management, absorptive capacity, dynamic capabilities
3. **Organizational Change**: Strategic renewal, restructuring, transformation, adaptation
4. **Organizational Culture**: Values, norms, cultural fit, cultural change
5. **Leadership & Governance**: CEO characteristics, board composition, executive compensation, ownership structure
6. **Human Capital**: Talent management, employee mobility, organizational capabilities
7. **Organizational Performance**: Financial performance, operational efficiency, market valuation, survival

## Phase 1: Theoretical Framework Development

### 1.1 Research Question Formulation

**Process**:
1. Identify the phenomenon of interest (e.g., "Why do some firms sustain competitive advantage?")
2. Review existing theories that might explain the phenomenon
3. Identify theoretical gaps or contradictions
4. Formulate specific, testable research questions

**Key Theories in Strategy Research**:

**Resource-Based View (RBV)**:
- Core texts: Barney (1991), Peteraf (1993), Wernerfelt (1984)
- Key concepts: VRIN resources, sustained competitive advantage, resource heterogeneity
- Applications: Explaining performance differences, competitive advantage sustainability

**Dynamic Capabilities**:
- Core texts: Teece, Pisano, & Shuen (1997), Eisenhardt & Martin (2000), Helfat et al. (2007)
- Key concepts: Sensing, seizing, reconfiguring; organizational agility
- Applications: Strategic change, innovation, adaptation to environmental shifts

**Industrial Organization (IO) Economics**:
- Core texts: Porter (1980, 1985), Caves & Porter (1977)
- Key concepts: Industry structure, five forces, strategic positioning
- Applications: Industry analysis, competitive positioning, profitability differences

**Transaction Cost Economics (TCE)**:
- Core texts: Williamson (1975, 1985, 1991), Coase (1937)
- Key concepts: Asset specificity, bounded rationality, opportunism, governance structures
- Applications: Make-or-buy decisions, vertical integration, alliance formation

**Agency Theory**:
- Core texts: Jensen & Meckling (1976), Fama & Jensen (1983)
- Key concepts: Principal-agent problem, information asymmetry, incentive alignment
- Applications: Corporate governance, executive compensation, board structure

**Stakeholder Theory**:
- Core texts: Freeman (1984), Mitchell, Agle, & Wood (1997)
- Key concepts: Stakeholder salience, stakeholder management, value creation for multiple constituencies
- Applications: CSR, ESG, sustainable competitive advantage

**Institutional Theory**:
- Core texts: DiMaggio & Powell (1983), Scott (1995), Oliver (1997)
- Key concepts: Isomorphism, legitimacy, institutional pressures
- Applications: Organizational conformity, strategic responses to institutional environments

**Network Theory**:
- Core texts: Granovetter (1985), Burt (1992), Gulati (1999)
- Key concepts: Social capital, structural holes, network embeddedness
- Applications: Alliance formation, inter-organizational relationships, knowledge transfer

**Organizational Ecology**:
- Core texts: Hannan & Freeman (1977, 1984), Carroll (1984)
- Key concepts: Selection, inertia, density dependence, niche width
- Applications: Organizational founding, failure, population dynamics

**Complementarity & Configurational Theories**:
- Core texts: Milgrom & Roberts (1995), Fiss (2007), Meyer et al. (1993)
- Key concepts: Organizational complementarities, fit, configurations, equifinality
- Applications: Organizational design, synergies, performance

### 1.2 Hypothesis Development

**Hypothesis Construction Principles**:
1. **Directionality**: Specify positive, negative, or curvilinear relationships
2. **Causality**: Clearly indicate independent and dependent variables
3. **Testability**: Ensure variables are measurable with available data
4. **Theoretical grounding**: Derive from established theories or novel theoretical arguments

**Example Hypotheses by Domain**:

**Competitive Strategy**:
```
H1: Firms with higher product differentiation achieve higher profitability than firms with lower differentiation.
H2: The relationship between market share and profitability is moderated by industry concentration.
H3: Firms pursuing focused strategies outperform generalists in turbulent environments.
```

**Innovation Strategy**:
```
H1: R&D intensity is positively associated with firm innovation output (patent counts).
H2: The relationship between R&D intensity and innovation output is inverted U-shaped.
H3: External knowledge acquisition moderates the R&D-innovation relationship positively.
```

**Organizational Design**:
```
H1: Organizational decentralization is positively related to firm responsiveness to market changes.
H2: The decentralization-performance relationship is stronger in dynamic environments.
H3: Structural complexity mediates the relationship between firm size and organizational inertia.
```

### 1.3 Variable Operationalization

**Dependent Variables (Examples)**:

**Financial Performance**:
- ROA (Return on Assets) = Net Income / Total Assets
- ROE (Return on Equity) = Net Income / Shareholders' Equity
- ROS (Return on Sales) = Operating Income / Sales Revenue
- Tobin's Q = (Market Value of Equity + Book Value of Debt) / Total Assets

**Market Performance**:
- Market Share = Firm Sales / Industry Sales
- Market Growth = (Current Year Market Share - Previous Year Market Share) / Previous Year Market Share
- Stock Returns = (Pt - Pt-1 + Dividends) / Pt-1

**Innovation Output**:
- Patent Counts = Number of patents granted in year t
- Citation-Weighted Patents = Σ(Patent Citations)
- New Product Introductions = Count of new products launched

**Organizational Outcomes**:
- Survival = Binary (1 if firm exists at year t, 0 otherwise)
- Employee Turnover Rate = (Employees Departed / Average Employees) × 100
- Organizational Growth = (Employeest - Employeest-1) / Employeest-1

**Independent Variables (Examples)**:

**Firm Characteristics**:
- Firm Size = log(Total Assets) or log(Employees)
- Firm Age = Current Year - Founding Year
- Leverage = Total Debt / Total Assets
- R&D Intensity = R&D Expenditure / Sales Revenue
- Advertising Intensity = Advertising Expenditure / Sales Revenue

**Strategic Variables**:
- Diversification = Entropy measure or Herfindahl index across business segments
- Geographic Diversification = Number of countries/regions operated
- Vertical Integration = Value added / Sales
- Alliance Portfolio Size = Count of active strategic alliances

**Governance Variables**:
- Board Size = Number of directors
- Board Independence = Independent Directors / Total Directors
- CEO Duality = Binary (1 if CEO also serves as board chair, 0 otherwise)
- Institutional Ownership = Shares held by institutions / Total shares

**Moderating Variables**:
- Industry Dynamism = Standard deviation of industry sales growth over past 5 years
- Industry Concentration = Herfindahl-Hirschman Index (HHI) = Σ(Market Sharei)²
- Technological Intensity = Industry R&D / Industry Sales
- Competitive Intensity = 1 - HHI

**Control Variables (Standard Set)**:
- Firm size (log assets or log employees)
- Firm age (log age)
- Leverage (debt/assets)
- Industry fixed effects (dummy variables)
- Year fixed effects (dummy variables)
- Country fixed effects (for international studies)

---

## Phase 2: Research Design & Data Requirements

### 2.1 Research Design Types

**Cross-Sectional Studies**:
- Single time point observation
- Suitable for: Exploring relationships, testing moderators
- Limitations: Cannot establish causality, reverse causality concerns
- Example: "Does board diversity affect firm innovation?" (data from 2023)

**Panel Data Studies**:
- Multiple time points, same firms
- Suitable for: Causal inference, controlling for unobserved heterogeneity
- Methods: Fixed effects, random effects, difference-in-differences
- Example: "How does R&D investment affect performance over 10 years?"

**Event Studies**:
- Pre-post comparison around a specific event
- Suitable for: M&A, CEO turnover, regulation changes, product launches
- Methods: Abnormal returns, difference-in-differences
- Example: "Stock market reaction to CEO succession announcements"

**Survival Analysis**:
- Time-to-event data (e.g., firm failure, CEO tenure)
- Suitable for: Organizational mortality, exit, duration models
- Methods: Cox proportional hazards, Kaplan-Meier
- Example: "What factors predict startup survival?"

**Quasi-Experimental Designs**:
- Natural experiments, difference-in-differences, regression discontinuity
- Suitable for: Causal inference when randomization is impossible
- Example: "Effect of minimum wage increase on firm employment strategies"

### 2.2 Sample Selection Criteria

**Defining the Population**:
1. **Industry Scope**:
   - Single industry: "U.S. pharmaceutical firms"
   - Multiple industries: "Manufacturing firms across 20 industries"
   - All industries: "Publicly traded firms in the U.S."

2. **Geographic Scope**:
   - Single country: "Japanese listed companies"
   - Regional: "European Union firms"
   - Global: "Firms from 50 countries"

3. **Firm Characteristics**:
   - Public vs. private
   - Large vs. SME (e.g., >$100M revenue, >500 employees)
   - Listed on stock exchange (NYSE, NASDAQ, TSE, etc.)

4. **Time Period**:
   - Historical: 1980-2000
   - Recent: 2010-2023
   - Length: Minimum 5 years for panel studies, 10+ years for long-run effects

5. **Data Availability**:
   - Financial data: Must be available in Compustat, Orbis, or equivalent
   - Industry classification: Consistent SIC or NAICS codes
   - Control variables: Complete data for key controls

### 2.3 Sample Size Determination

**General Guidelines**:
- **Regression analysis**: Minimum 10-15 observations per predictor variable
- **Panel data**: Minimum 100 firms × 5 years = 500 observations
- **Event studies**: Minimum 50-100 events for sufficient statistical power
- **Survival analysis**: Depends on event rate; minimum 50-100 events (failures)

**Power Analysis**:
- Specify: Effect size, significance level (α = 0.05), power (1-β = 0.80)
- Calculate required sample size using G*Power or similar tools
- Account for missing data (add 10-20% buffer)

---

## Phase 3: Data Source Discovery & Evaluation

### 3.1 Primary Data Sources for Strategy Research

#### A. Financial & Market Data

**North America (Primary Focus)**:

1. **Compustat (via WRDS)**
   - Coverage: U.S. & Canadian public companies (1950-present)
   - Data: Balance sheets, income statements, cash flows, segment data
   - Access: University subscription via WRDS
   - Key Variables: Total assets, sales, net income, R&D, advertising, CAPEX, employees
   - Industry Classification: SIC (4-digit), GICS
   - Strengths: High quality, long history, comprehensive coverage
   - Limitations: Survivorship bias, U.S.-centric

2. **CRSP (Center for Research in Security Prices)**
   - Coverage: U.S. stock market (1926-present), all exchanges
   - Data: Daily/monthly stock prices, returns, trading volume, market cap
   - Access: Via WRDS
   - Key Variables: Returns, volatility, Tobin's Q components
   - Strengths: No survivorship bias, adjusted for splits/dividends
   - Use Cases: Event studies, market-based performance, abnormal returns

3. **Compustat/CRSP Merged Database (CCM)**
   - Combines financial (Compustat) and market (CRSP) data
   - Link via PERMNO-GVKEY crosswalk
   - Essential for studies using both accounting and market data

**Europe**:

1. **Bureau van Dijk - Orbis**
   - Coverage: 400M+ companies globally, strong European coverage
   - Data: Financials, ownership, subsidiaries, M&A, patents
   - Access: University or direct subscription
   - Strengths: Private and public firms, ownership structures, 40+ years
   - Limitations: Data quality varies by country, limited U.S. coverage
   - Best for: European research, SME studies, ownership analysis

2. **Amadeus (BvD)**
   - European subset of Orbis (detailed)
   - Financials for 21 million European companies
   - Deep historical data for major European countries

3. **Datastream (Refinitiv)**
   - Coverage: Global market data, 175 countries
   - Data: Stock prices, indices, financials, analyst forecasts
   - Access: Subscription
   - Strengths: Real-time + historical, global coverage
   - Use Cases: International studies, cross-country comparisons

**Asia-Pacific**:

1. **Japan: NEEDS-FinancialQUEST (Nikkei)**
   - Coverage: Japanese listed companies (1950s-present)
   - Data: Financials, stock prices, corporate actions, segments
   - Access: Nikkei subscription
   - Language: Japanese interface, data in Japanese accounting standards
   - Essential for: Japan-focused strategy research

2. **Japan: SPEEDA (Uzabase)**
   - Coverage: 3M+ companies in Asia-Pacific
   - Data: Financials, industry analysis, M&A, market trends
   - Strengths: English interface, industry reports, real-time updates
   - Free Alternative: Japan Corporate Number (法人番号公表サイト) for basic firm info

3. **China: CSMAR (China Stock Market & Accounting Research)**
   - Coverage: Chinese listed companies (1990-present)
   - Data: Financials, market data, governance, IPOs
   - Access: Subscription (universities in China often have)
   - Note: Requires understanding of Chinese accounting standards (CAS)

4. **Taiwan: Taiwan Economic Journal (TEJ)**
   - Coverage: Taiwanese listed companies
   - Data: Comprehensive financials, market data, corporate governance
   - Access: Subscription

5. **India: CMIE Prowess**
   - Coverage: 40,000+ Indian companies
   - Data: Financials, ownership, projects, directors
   - Access: Subscription
   - Strengths: Public + private firms

6. **South Korea: FnGuide, Kis-Value**
   - Coverage: Korean listed companies
   - Data: Financials, market data, analyst forecasts
   - Access: Subscription

**Global Multi-Country**:

1. **Thomson Reuters Worldscope**
   - Coverage: 70+ countries, 70,000+ companies
   - Data: Standardized financials (comparable across countries)
   - Strengths: Cross-country consistency, accounting adjustments
   - Limitations: Expensive, less detailed than country-specific databases

2. **FactSet**
   - Coverage: Global companies, real-time + historical
   - Data: Financials, ownership, estimates, transcripts, supply chains
   - Access: Expensive subscription
   - Strengths: High-frequency data, supply chain data

3. **S&P Global Market Intelligence (Capital IQ)**
   - Coverage: Global companies, private equity
   - Data: Financials, transactions, owners, estimates
   - Strengths: Private company data, M&A details

#### B. Specialized Data for Strategy Research

**Innovation & Patents**:

1. **USPTO PatentsView (Free)**
   - Coverage: All U.S. patents (1976-present), 10M+ patents
   - Data: Patents, citations, inventors, assignees, classifications (CPC, IPC)
   - Access: Free bulk download or API
   - URL: https://patentsview.org/
   - Integration: Match to Compustat via company names/subsidiaries
   - Key Variables: Patent counts, citation-weighted patents, technology classes

2. **PATSTAT (European Patent Office)**
   - Coverage: Global patents from 90+ offices
   - Data: Applications, grants, citations, families
   - Access: Subscription (~€1,000-2,000/year) or DVD
   - Strengths: Comprehensive global coverage

3. **Google Patents (Free)**
   - Coverage: Global patents, USPTO, EPO, WIPO
   - Search interface for patent text, citations, legal status
   - URL: https://patents.google.com/

4. **NBER Patent Database (Free for research)**
   - Coverage: U.S. patents linked to Compustat firms
   - Data: Patent-firm matching (1976-2006)
   - Citation: Hall, Jaffe, & Trajtenberg (2001)
   - URL: https://sites.google.com/site/patentdataproject/

5. **Kogan et al. Patent Value Dataset (Free)**
   - Coverage: U.S. patents with market-based valuations (1926-2010)
   - Data: Patent value estimated from stock market reactions
   - Citation: Kogan, Papanikolaou, Seru, & Stoffman (2017)
   - URL: http://iu.box.com/v/patents

**ESG & Sustainability**:

1. **MSCI ESG Ratings**
   - Coverage: 14,000+ companies globally
   - Data: Environmental, social, governance scores (AAA to CCC)
   - Access: Expensive subscription ($50K+/year)
   - Alternative: Free ESG risk ratings from Sustainalytics (limited)

2. **Refinitiv (Thomson Reuters) ESG Scores**
   - Coverage: 11,000+ companies
   - Data: 630+ ESG metrics, controversy scores
   - Access: Expensive subscription
   - Strengths: Detailed metrics, long time series

3. **CDP (Carbon Disclosure Project) (Free for researchers)**
   - Coverage: 13,000+ companies responding to climate surveys
   - Data: Carbon emissions (Scope 1, 2, 3), climate strategy, targets
   - Access: Apply for academic license (free)
   - URL: https://www.cdp.net/en/academic-research

4. **Sustainalytics ESG Risk Ratings (Free - limited)**
   - Coverage: 20,000+ companies
   - Data: ESG risk scores (0-100), controversy assessments
   - Access: Free basic ratings via Yahoo Finance or Morningstar
   - Paid: Full database subscription

5. **GRI Sustainability Disclosure Database (Free)**
   - Coverage: 60,000+ sustainability reports from 15,000+ organizations
   - Access: Free search and download
   - URL: https://database.globalreporting.org/

6. **Bloomberg ESG Data**
   - Coverage: 10,000+ companies
   - Data: 900+ ESG metrics
   - Access: Expensive (Bloomberg Terminal required)

**Mergers & Acquisitions**:

1. **SDC Platinum (Thomson Reuters) (via WRDS)**
   - Coverage: Global M&A, IPOs, joint ventures (1970s-present)
   - Data: Deal values, targets, acquirers, advisors, deal structure
   - Access: Via WRDS (university subscription)
   - Key Variables: Transaction value, deal type, payment method, completion status

2. **Bureau van Dijk - Zephyr**
   - Coverage: Global M&A, IPO, venture capital (1997-present)
   - Data: Deal details, involved parties, financials
   - Access: Subscription
   - Strengths: European M&A coverage better than SDC

3. **CapitalIQ Transactions**
   - Coverage: Global M&A, PE, VC deals
   - Access: Expensive subscription

**Free Alternative for M&A Data**:
- **SEC EDGAR** (U.S.): Search for Form 8-K (current reports), DEF 14A (proxy statements)
- **Company press releases**: Often announce M&A publicly

**Corporate Governance & Ownership**:

1. **ExecuComp (via WRDS)**
   - Coverage: S&P 1500 executives (1992-present)
   - Data: Executive compensation, board characteristics, insider trading
   - Access: Via WRDS
   - Key Variables: CEO/executive pay, equity holdings, board size, independence
   - Integration: Links to Compustat via GVKEY

2. **ISS (Institutional Shareholder Services) Directors**
   - Coverage: U.S. board composition, voting results
   - Data: Director characteristics, committee memberships, voting
   - Access: Expensive subscription

3. **Thomson Reuters 13F (via WRDS)**
   - Coverage: U.S. institutional ownership (1980-present)
   - Data: Quarterly holdings of institutions with >$100M AUM
   - Access: Via WRDS
   - Key Variables: Institutional ownership %, number of institutions

4. **Orbis Ownership Module**
   - Coverage: Global ownership structures
   - Data: Ultimate owners, ownership percentages, subsidiaries
   - Strengths: Private and public firms, complex ownership chains

**Free Alternative**:
- **SEC EDGAR**: Form 4 (insider trading), Schedule 13D/13G (5%+ ownership)
- **Japan: EDINET** (金融商品取引法に基づく有価証券報告書等の開示書類に関する電子開示システム)

**Analyst Forecasts & Recommendations**:

1. **I/B/E/S (Institutional Brokers' Estimate System) (via WRDS)**
   - Coverage: Global analyst forecasts (1976-present)
   - Data: Earnings estimates, recommendations, price targets
   - Access: Via WRDS
   - Key Variables: Consensus EPS forecast, analyst dispersion, recommendation changes
   - Use Cases: Analyst coverage, forecast errors, market expectations

**Industry & Market Data**:

1. **World Bank Open Data (Free)**
   - Coverage: 200+ countries, 1960-present
   - Data: GDP, inflation, trade, governance indicators (WGI), doing business
   - URL: https://data.worldbank.org/
   - API: Yes (R, Python, Stata packages available)
   - Key Variables: GDP growth, institutional quality, regulatory environment

2. **OECD Data (Free)**
   - Coverage: OECD countries + partners
   - Data: Economic indicators, industry statistics, productivity
   - URL: https://data.oecd.org/
   - API: Yes
   - Key Variables: Industry R&D, productivity, trade flows

3. **Fama-French Data Library (Free)**
   - Coverage: U.S. market factors (1926-present), global (1990-present)
   - Data: Market, size, value, profitability, investment factors
   - URL: https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html
   - Use Cases: Risk-adjusted returns, factor analysis

4. **Federal Reserve Economic Data (FRED) (Free)**
   - Coverage: U.S. macroeconomic data
   - Data: Interest rates, inflation, GDP, unemployment, industry production
   - URL: https://fred.stlouisfed.org/
   - API: Yes
   - Key Variables: Risk-free rate, inflation, GDP growth

5. **U.S. Census Bureau (Free)**
   - Coverage: U.S. economic data
   - Data: Economic census (every 5 years), industry statistics, business dynamics
   - URL: https://www.census.gov/data.html
   - Key Variables: Industry concentration, firm births/deaths

6. **Eurostat (Free)**
   - Coverage: European Union statistical data
   - URL: https://ec.europa.eu/eurostat

**Strategic Alliances & Networks**:

1. **SDC Platinum Joint Ventures/Alliances (via WRDS)**
   - Coverage: Global alliances, joint ventures (1985-present)
   - Data: Partners, deal structure, industries
   - Access: Via WRDS

2. **Recap IQ (alliance database)**
   - Coverage: Pharmaceutical, biotech, medical device alliances
   - Access: Expensive subscription

**Free Alternative**:
- **News archives**: Search for alliance announcements (Factiva, LexisNexis)
- **Company press releases**

**Board Interlocks**:

1. **BoardEx**
   - Coverage: Global board interlocks, executive networks
   - Data: Director profiles, employment history, education, connections
   - Access: Expensive subscription
   - Use Cases: Board network studies, director labor market

**Text & Sentiment Data**:

1. **Conference Call Transcripts**
   - Source: FactSet, Bloomberg, Refinitiv, SeekingAlpha (some free)
   - Use: Text analysis, managerial sentiment, strategic communication

2. **Annual Reports (10-K, 10-Q)**
   - Source: SEC EDGAR (free), EDINET (Japan, free)
   - Use: Text analysis, MD&A (Management Discussion & Analysis), risk factors

3. **News Articles**
   - Source: Factiva, LexisNexis, Bloomberg News (all subscriptions)
   - Free Alternative: Google News Archives (limited)

**Alternative & Emerging Data Sources**:

1. **Web Scraping**
   - LinkedIn: Employee counts, job postings (use API or scraping with caution - ToS)
   - Glassdoor: Employee reviews, firm culture data
   - Crunchbase: Startup funding, founders, investors
   - PitchBook: Venture capital, private equity data

2. **Satellite Imagery**
   - Providers: Orbital Insight, RS Metrics
   - Use: Real-time economic activity (parking lot traffic, store openings)
   - Cost: Very expensive

3. **Credit Card Transactions (Aggregated)**
   - Providers: Envestnet Yodlee, Earnest Research, Facteus
   - Use: Consumer spending patterns
   - Cost: Very expensive
   - Ethical: Ensure anonymization and compliance

4. **Job Postings Data**
   - Source: Burning Glass Technologies, LinkedIn Talent Insights
   - Use: Firm growth, skill requirements, organizational changes
   - Access: Subscription

### 3.2 Free & Low-Cost Data Sources (Zero-Budget Research)

For researchers without access to expensive commercial databases, the following free sources enable high-quality research:

**Firm-Level Data (Free)**:

1. **SEC EDGAR (U.S.)** - https://www.sec.gov/edgar
   - Forms: 10-K (annual), 10-Q (quarterly), 8-K (current events), DEF 14A (proxy)
   - Data: Financials, executive compensation, ownership, board composition, segments
   - How to use: Download via EDGAR crawler or use `edgartools` Python package

2. **EDINET (Japan)** - https://disclosure2.edinet-fsa.go.jp/
   - Japanese equivalent of SEC EDGAR
   - Data: 有価証券報告書 (annual reports), 四半期報告書 (quarterly)
   - Language: Japanese (use translation tools)

3. **OpenCorporates** - https://opencorporates.com/
   - Coverage: 200M+ companies globally
   - Data: Basic firm info, registration, directors
   - Free: Basic search; API requires subscription

4. **Company Websites & Investor Relations**
   - Financial statements, annual reports, ESG reports
   - Press releases for M&A, alliances, product launches

**Patent Data (Free)**:

1. **USPTO PatentsView** - https://patentsview.org/
2. **Google Patents** - https://patents.google.com/
3. **WIPO PatentScope** - https://patentscope.wipo.int/
4. **EPO Espacenet** - https://worldwide.espacenet.com/

**ESG Data (Free)**:

1. **CDP (academic license)** - https://www.cdp.net/en/academic-research
2. **GRI Database** - https://database.globalreporting.org/
3. **Yahoo Finance ESG Scores** - https://finance.yahoo.com/ (Sustainalytics data)

**Macroeconomic & Industry Data (Free)**:

1. **World Bank** - https://data.worldbank.org/
2. **OECD** - https://data.oecd.org/
3. **FRED** - https://fred.stlouisfed.org/
4. **IMF Data** - https://data.imf.org/
5. **UN Data** - http://data.un.org/
6. **Eurostat** - https://ec.europa.eu/eurostat

**Zero-Budget Research Strategy**:

Example: "Analyzing the effect of R&D on firm performance in Japanese electronics firms"

**Data Collection Plan (All Free)**:
1. **Financials**: EDINET (Japanese 有価証券報告書)
2. **Patents**: USPTO PatentsView (Japanese firms patenting in U.S.)
3. **Industry Data**: OECD Industry Statistics (electronics industry trends)
4. **Macroeconomic Controls**: World Bank (Japan GDP growth, inflation)
5. **Firm Events**: Company press releases, news (Google News)

**Total Cost**: $0 (except time for data collection and cleaning)

### 3.3 Data Source Evaluation Matrix

For each potential data source, evaluate:

| Criterion | Description | Weight | Score (1-5) |
|-----------|-------------|--------|-------------|
| **Coverage** | Does it cover your sample (time, geography, firms)? | 30% | |
| **Accessibility** | Can you access it (cost, university access, free)? | 25% | |
| **Quality** | Completeness, reliability, documentation quality | 20% | |
| **Format** | Ease of use (API, CSV, Excel, PDF) | 10% | |
| **Update Frequency** | How often is data updated? | 10% | |
| **Integration** | Can it be easily merged with other sources? | 5% | |

**Scoring**:
- 5 = Excellent
- 4 = Good
- 3 = Adequate
- 2 = Poor
- 1 = Unacceptable

**Weighted Score** = Σ(Weight × Score)

**Decision Rule**:
- Weighted Score ≥ 4.0: Highly recommended
- 3.0-3.9: Acceptable
- <3.0: Consider alternatives

---

## Phase 4: Data Collection Strategy Design

### 4.1 Data Collection Methods

**A. API-Based Collection (Preferred for large datasets)**

**Advantages**:
- Automated, reproducible
- Real-time or scheduled updates
- Structured data format (JSON, XML)

**Common APIs**:
- WRDS: Python `wrds` package, SAS access
- World Bank: `wbdata` (Python), `WDI` (R)
- FRED: `fredapi` (Python), `fredr` (R)
- USPTO: PatentsView API
- SEC EDGAR: `edgartools` (Python)

**Example Python Code (WRDS Compustat)**:
```python
import wrds
db = wrds.Connection()

# Query Compustat fundamentals
query = """
SELECT gvkey, datadate, fyear, at, sale, ni, emp, xrd
FROM comp.funda
WHERE indfmt='INDL' AND datafmt='STD' AND popsrc='D' AND consol='C'
AND fyear BETWEEN 2010 AND 2023
AND at IS NOT NULL
"""
df = db.raw_sql(query)
db.close()
```

**B. Bulk Download**

**Use When**: API rate limits, large historical downloads
**Process**:
1. Check if bulk download available (e.g., PatentsView, World Bank)
2. Download entire dataset or filtered subset
3. Import into Python/R/Stata
4. Filter and clean locally

**C. Web Scraping (Use Responsibly)**

**Legal Considerations**:
- Check website Terms of Service
- Respect robots.txt
- Use reasonable request rates (delays)
- Do not scrape personal data

**Tools**:
- Python: `requests`, `BeautifulSoup`, `Selenium`, `Scrapy`
- R: `rvest`, `RSelenium`

**Example (company website)**:
```python
import requests
from bs4 import BeautifulSoup
import time

url = "https://example.com/company-info"
response = requests.get(url)
soup = BeautifulSoup(response.content, 'html.parser')
company_name = soup.find('h1', class_='company-name').text
time.sleep(2)  # Be respectful, don't overload servers
```

**D. Manual Data Entry (Last Resort)**

**Use When**: Small sample, no digital source available
**Process**:
1. Create Excel template with variable names
2. Establish coding rules for consistency
3. Double-entry for accuracy (two people enter independently)
4. Reconcile discrepancies

### 4.2 Data Collection Workflow

**Step 1: Pilot Data Collection (1 week)**
- Collect data for 10-20 firms or 1-2 years
- Test variable availability and data quality
- Identify issues early (missing data, format problems)

**Step 2: Full Data Collection (2-8 weeks)**
- Execute API queries, bulk downloads, or scraping
- Save raw data immediately (never overwrite)
- Document any deviations from plan

**Step 3: Data Logging**
- Record: Source, date accessed, query used, sample restrictions
- Example log entry:
  ```
  Date: 2025-10-31
  Source: Compustat via WRDS
  Query: comp.funda, fyear 2010-2023, INDL format
  Sample: 15,234 firm-year observations
  Missing: xrd (R&D) missing for 3,421 obs (22%)
  Action: Will control for R&D reporting in analysis
  ```

### 4.3 Multi-Source Data Integration

**Challenge**: Merging data from multiple databases with different firm identifiers

**Common Identifiers**:
- **GVKEY** (Compustat standard)
- **PERMNO** (CRSP standard)
- **CUSIP** (9-digit: Committee on Uniform Securities Identification Procedures)
- **ISIN** (International Securities Identification Number)
- **Ticker Symbol** (not unique over time, avoid as primary key)
- **Company Name** (requires fuzzy matching, error-prone)

**Linkage Tables**:
1. **CRSP-Compustat Merged (CCM Link)** - via WRDS
2. **PERMNO-CUSIP-Ticker crosswalk** - via CRSP
3. **Patent-Compustat Link** - via NBER or manual matching

**Matching Strategies**:

**A. Exact Match (Preferred)**:
```python
merged_df = pd.merge(df_compustat, df_patents, 
                     on='gvkey', how='inner')
```

**B. Fuzzy Matching (Company Names)**:
```python
from fuzzywuzzy import process

# Example: Match "International Business Machines" to "IBM Corp"
best_match = process.extractOne("IBM Corp", company_names_list)
```

**C. Manual Review**:
- For critical matches (M&A, alliances), manually verify
- Create a "match_confidence" column: High/Medium/Low
- Exclude Low confidence matches or perform robustness checks

**Validation After Merge**:
- Check record counts: Expected vs. actual
- Identify duplicates: `df.duplicated(['firm_id', 'year']).sum()`
- Inspect unmatched observations: Why did they not match?

---

## Phase 5: Data Cleaning & Preparation

### 5.1 Standard Data Cleaning Steps

**Step 1: Initial Inspection**
```python
# Load data
import pandas as pd
df = pd.read_csv('compustat_raw.csv')

# Basic inspection
df.info()                 # Data types, missing values
df.describe()             # Summary statistics
df.head(20)               # First rows
df.isnull().sum()         # Count missing per variable
```

**Step 2: Handle Missing Data**

**A. Understand Missingness**:
- **Missing Completely at Random (MCAR)**: Missingness unrelated to any variables
- **Missing at Random (MAR)**: Missingness related to observed variables
- **Missing Not at Random (MNAR)**: Missingness related to unobserved factors

**B. Strategies**:
1. **Listwise deletion**: Drop observations with any missing data (reduces sample)
2. **Variable-specific deletion**: Drop only when key variables are missing
3. **Imputation**: 
   - Mean/median imputation (for MCAR)
   - Carry forward/backward (for time series)
   - Multiple imputation (for MAR) - use `sklearn.IterativeImputer` or `mice` in R
4. **Indicator method**: Create dummy = 1 if missing, include in regression

**Example**:
```python
# Drop if key variables missing
df = df.dropna(subset=['at', 'sale', 'ni'])  # assets, sales, net income

# Impute R&D (often missing if firm doesn't report)
df['xrd'] = df['xrd'].fillna(0)  # Assume 0 if not reported
df['xrd_missing'] = df['xrd'].isnull().astype(int)  # Indicator
```

**Step 3: Outlier Detection & Treatment**

**A. Identify Outliers**:
- **Univariate**: Box plots, z-scores (|z| > 3), percentiles (< 1%, > 99%)
- **Bivariate**: Scatter plots, Cook's distance, DFFITS

```python
# Identify extreme values
df['roa'] = df['ni'] / df['at']  # ROA
df['roa'].describe(percentiles=[0.01, 0.05, 0.95, 0.99])

# Flag outliers (z-score method)
from scipy import stats
df['roa_zscore'] = stats.zscore(df['roa'])
outliers = df[abs(df['roa_zscore']) > 3]
print(f"Outliers: {len(outliers)} ({len(outliers)/len(df)*100:.2f}%)")
```

**B. Treatment**:
1. **Winsorize**: Cap at 1st and 99th percentiles (common in finance)
2. **Trim**: Remove extreme values (justify threshold)
3. **Transform**: Log, square root (if distribution is skewed)
4. **Keep**: If genuine and important (e.g., Tesla's high valuation)

```python
# Winsorize at 1% and 99%
from scipy.stats.mstats import winsorize
df['roa_winsorized'] = winsorize(df['roa'], limits=[0.01, 0.01])
```

**Decision Rule**: Winsorization is standard in strategy research. Trim only if outliers are errors.

**Step 4: Variable Construction**

**A. Transformations**:
```python
# Log transformations (for skewed variables)
df['log_assets'] = np.log(df['at'])
df['log_employees'] = np.log(df['emp'] + 1)  # +1 to handle zeros

# Standardization (mean=0, sd=1)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df['roa_std'] = scaler.fit_transform(df[['roa']])

# Lagged variables (for panel data)
df = df.sort_values(['gvkey', 'fyear'])
df['roa_lag1'] = df.groupby('gvkey')['roa'].shift(1)
```

**B. Industry Classification**:
```python
# Convert SIC to 2-digit industry
df['sic2'] = df['sic'].astype(str).str[:2]

# Create industry dummies
df = pd.get_dummies(df, columns=['sic2'], prefix='ind', drop_first=True)
```

**Step 5: Time Alignment**

**Issue**: Financial data (fiscal year-end) vs. market data (calendar year)
**Solution**: Align based on fiscal year-end date

```python
# Ensure financial data is matched to correct calendar year
# If fiscal year ends in Dec 2023, match to 2023
# If fiscal year ends in Mar 2024, match to 2023 (data available in 2024)

df['calendar_year'] = df.apply(lambda row: 
    row['fyear'] if row['datadate'].month == 12 else row['fyear'] - 1, 
    axis=1)
```

### 5.2 Panel Data Specific Issues

**Issue 1: Unbalanced Panel**
- Not all firms have data for all years
- **Solution**: Use fixed effects or random effects (handles unbalanced panels)
- **Report**: "Unbalanced panel: 1,234 firms, 5-15 years per firm, 12,345 firm-years"

**Issue 2: Attrition Bias**
- Firms drop out due to failure, acquisition, going private
- **Solution**: 
  - Use Heckman selection model
  - Include "survival" as a dependent variable (survival analysis)
  - Report attrition rates and compare survivors vs. non-survivors

**Issue 3: Firm-Level Heterogeneity**
- Unobserved firm characteristics affecting outcome
- **Solution**: Fixed effects regression (controls for time-invariant unobserved factors)

```python
# Fixed effects regression in Python (using linearmodels)
from linearmodels import PanelOLS

df = df.set_index(['gvkey', 'fyear'])
model = PanelOLS(df['roa'], df[['log_assets', 'leverage', 'xrd_intensity']], 
                 entity_effects=True, time_effects=True)
results = model.fit(cov_type='clustered', cluster_entity=True)
print(results)
```

### 5.3 Final Dataset Creation

**Checklist Before Analysis**:
- [ ] All variables correctly defined and labeled
- [ ] Missing data handled appropriately
- [ ] Outliers addressed (winsorized or trimmed)
- [ ] Industry and year dummies created
- [ ] Sample restrictions applied (e.g., exclude financials, utilities)
- [ ] Lagged variables created (if needed)
- [ ] Descriptive statistics computed
- [ ] Data dictionary completed

**Create Data Dictionary**:
```
Variable Name | Description | Source | Unit | Missing (%) | Mean | SD
-------------|-------------|--------|------|------------|------|----
gvkey        | Firm ID     | Compustat | - | 0% | - | -
fyear        | Fiscal year | Compustat | Year | 0% | 2016.5 | 4.2
at           | Total assets | Compustat | $M | 0% | 15234 | 45678
roa          | ROA (NI/TA) | Computed | Ratio | 2.3% | 0.045 | 0.12
log_assets   | Log(assets) | Computed | - | 0% | 7.85 | 1.95
```

**Save Final Dataset**:
```python
# Save cleaned data
df.to_csv('data_final_cleaned.csv', index=False)
df.to_stata('data_final_cleaned.dta')  # For Stata users

# Save data dictionary
data_dict.to_excel('data_dictionary.xlsx', index=False)
```

---

## Phase 6: Statistical Analysis for Strategy Research

### 6.1 Descriptive Statistics

**Purpose**: Describe sample characteristics, check data quality

**Tables to Generate**:

**Table 1: Sample Composition**
```
Industry (SIC 2-digit)     | N firms | % of sample | Avg ROA
---------------------------|---------|-------------|--------
Manufacturing (20-39)      | 450     | 36.5%       | 0.042
Services (70-89)           | 320     | 26.0%       | 0.055
...
```

**Table 2: Descriptive Statistics**
```
Variable      | N     | Mean  | SD    | Min   | 25%   | 50%   | 75%   | Max
--------------|-------|-------|-------|-------|-------|-------|-------|------
ROA           | 5000  | 0.045 | 0.12  | -0.35 | 0.01  | 0.05  | 0.10  | 0.42
Log Assets    | 5000  | 7.85  | 1.95  | 3.2   | 6.5   | 7.8   | 9.1   | 14.2
R&D Intensity | 4100  | 0.032 | 0.05  | 0     | 0     | 0.01  | 0.05  | 0.25
```

**Table 3: Correlation Matrix**
```
          | ROA   | Size  | Leverage | R&D
----------|-------|-------|----------|------
ROA       | 1.00  |       |          |
Size      | 0.15* | 1.00  |          |
Leverage  | -0.22*| 0.35* | 1.00     |
R&D       | 0.08* | 0.12* | -0.15*   | 1.00
* p < 0.05
```

**Interpretation**:
- Check for multicollinearity: Correlation > 0.8 is concerning
- Compute VIF (Variance Inflation Factor): VIF > 10 indicates multicollinearity

```python
from statsmodels.stats.outliers_influence import variance_inflation_factor

# Compute VIF
X = df[['log_assets', 'leverage', 'xrd_intensity']]
vif = pd.DataFrame()
vif['Variable'] = X.columns
vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]
print(vif)
```

### 6.2 Regression Analysis

**A. OLS (Ordinary Least Squares) Regression**

**Use When**: Cross-sectional data, no panel structure

**Model Specification**:
```
Y_i = β0 + β1*X1_i + β2*X2_i + ... + Controls + ε_i
```

**Example (Stata)**:
```stata
regress roa log_assets leverage xrd_intensity i.industry i.year, robust
```

**Example (Python)**:
```python
import statsmodels.api as sm

# Prepare data
X = df[['log_assets', 'leverage', 'xrd_intensity']]
X = pd.get_dummies(X, columns=['industry', 'year'], drop_first=True)
X = sm.add_constant(X)
y = df['roa']

# Run regression
model = sm.OLS(y, X).fit(cov_type='HC1')  # Robust SE
print(model.summary())
```

**Results Reporting**:
- Coefficients, standard errors (robust), t-statistics, p-values
- R²,adjusted R²
- F-statistic (overall model significance)
- N (sample size)

**B. Panel Data Regressions**

**Fixed Effects (FE)**:
- Controls for time-invariant unobserved firm heterogeneity
- Estimates within-firm effects only
- Use when: Correlation between X and unobserved firm effects

**Model**:
```
Y_it = β1*X_it + α_i + δ_t + ε_it

where:
α_i = firm fixed effects
δ_t = year fixed effects
```

**Stata**:
```stata
xtset gvkey fyear
xtreg roa log_assets leverage xrd_intensity i.fyear, fe vce(cluster gvkey)
```

**Python**:
```python
from linearmodels import PanelOLS

df_panel = df.set_index(['gvkey', 'fyear'])
model = PanelOLS(df_panel['roa'], 
                 df_panel[['log_assets', 'leverage', 'xrd_intensity']], 
                 entity_effects=True, time_effects=True)
results = model.fit(cov_type='clustered', cluster_entity=True)
print(results)
```

**Random Effects (RE)**:
- Assumes unobserved effects are uncorrelated with X
- More efficient than FE if assumption holds
- Use Hausman test to choose between FE and RE

**Stata**:
```stata
xtreg roa log_assets leverage xrd_intensity i.fyear, re vce(cluster gvkey)
hausman fe re  # Test FE vs. RE
```

**Interpretation**:
- If Hausman test rejects (p < 0.05): Use FE
- If Hausman test fails to reject (p > 0.05): RE is consistent and more efficient

**C. Difference-in-Differences (DiD)**

**Use When**: Natural experiment or policy change affecting some firms (treated) but not others (control)

**Model**:
```
Y_it = β0 + β1*Treated_i + β2*Post_t + β3*(Treated_i × Post_t) + Controls + ε_it

where:
Treated_i = 1 if firm is in treatment group
Post_t = 1 if year is after treatment
β3 = DiD estimate (treatment effect)
```

**Example**: Effect of adopting new accounting standard on firm performance

**Stata**:
```stata
regress roa treated post treated_post log_assets leverage i.industry, robust
```

**Assumptions**:
- **Parallel trends**: Treatment and control groups would have followed similar trends absent treatment
- Test: Plot pre-treatment trends for both groups

```python
import matplotlib.pyplot as plt

pre_treatment = df[df['fyear'] < 2015]
sns.lineplot(data=pre_treatment, x='fyear', y='roa', hue='treated')
plt.title('Parallel Trends Test')
plt.show()
```

**D. Instrumental Variables (IV) / 2SLS**

**Use When**: Endogeneity concerns (reverse causality, omitted variables)

**Example**: Does R&D cause innovation (patents)? 
- Problem: Innovative firms may choose to invest more in R&D (reverse causality)
- Solution: Use an instrument (e.g., R&D tax credit changes) that affects R&D but not directly patents

**Model**:
```
First stage:  R&D_it = γ0 + γ1*Instrument_it + Controls + u_it
Second stage: Patents_it = β0 + β1*R&D_hat_it + Controls + ε_it
```

**Stata**:
```stata
ivregress 2sls patents (xrd = tax_credit) log_assets leverage i.industry i.year, robust
```

**Python**:
```python
from linearmodels.iv import IV2SLS

model = IV2SLS(dependent=df['patents'],
               exog=df[['log_assets', 'leverage']],
               endog=df[['xrd']],
               instruments=df[['tax_credit']]).fit()
print(model.summary)
```

**Instrument Validity Tests**:
- **Relevance**: First-stage F-statistic > 10 (instrument is strong)
- **Exogeneity**: Over-identification test (if multiple instruments)

### 6.3 Moderation & Mediation Analysis

**A. Moderation (Interaction Effects)**

**Research Question**: Does the effect of X on Y depend on Z?

**Model**:
```
Y = β0 + β1*X + β2*Z + β3*(X × Z) + Controls + ε

where:
β3 = moderation effect (how Z affects the X→Y relationship)
```

**Example**: Does environmental dynamism moderate the R&D-performance relationship?

```stata
gen xrd_dynamism = xrd * env_dynamism
regress roa xrd env_dynamism xrd_dynamism log_assets leverage i.industry i.year, robust
```

**Interpretation**:
- If β3 > 0 and significant: Z strengthens the positive effect of X on Y
- If β3 < 0 and significant: Z weakens (or reverses) the effect of X on Y

**Visualization** (Simple Slopes):
```python
# Plot interaction
low_z = df['env_dynamism'].quantile(0.25)
high_z = df['env_dynamism'].quantile(0.75)

plt.plot(x_range, β1*x_range + β3*x_range*low_z, label='Low Dynamism')
plt.plot(x_range, β1*x_range + β3*x_range*high_z, label='High Dynamism')
plt.xlabel('R&D Intensity')
plt.ylabel('ROA')
plt.legend()
plt.show()
```

**B. Mediation Analysis**

**Research Question**: Does M mediate the effect of X on Y?

**Steps**:
1. Test if X → Y (total effect, c)
2. Test if X → M (path a)
3. Test if M → Y, controlling for X (path b)
4. Test if X → Y, controlling for M (direct effect, c')

**Mediation exists if**: a and b are significant, and c' < c (partial mediation) or c' ≈ 0 (full mediation)

**Stata (using `mediate` command)**:
```stata
mediate (M ~ X controls) (Y ~ M X controls), treat(X) mediator(M)
```

**Python (using `mediation` package)**:
```python
from mediation import Mediation

med = Mediation(data=df, 
                treatment='X', 
                mediator='M', 
                outcome='Y', 
                controls=['log_assets', 'leverage'])
results = med.fit()
print(results.summary())
```

### 6.4 Advanced Methods

**A. Survival Analysis (Cox Proportional Hazards)**

**Use When**: Studying time to event (firm failure, CEO turnover, alliance dissolution)

**Model**:
```
h(t) = h0(t) * exp(β1*X1 + β2*X2 + ...)

where h(t) = hazard rate at time t
```

**Stata**:
```stata
stset year, failure(exit) id(gvkey)
stcox log_assets leverage xrd_intensity, robust
```

**Python**:
```python
from lifelines import CoxPHFitter

cph = CoxPHFitter()
cph.fit(df, duration_col='tenure', event_col='exit', 
        formula='log_assets + leverage + xrd_intensity')
cph.print_summary()
```

**Interpretation**:
- Hazard Ratio (HR) = exp(β)
- HR > 1: X increases hazard (shorter survival)
- HR < 1: X decreases hazard (longer survival)

**B. Event Study (Abnormal Returns)**

**Use When**: Measuring stock market reaction to events (M&A, CEO change, product launch)

**Steps**:
1. Define event window (e.g., [-1, +1] days around announcement)
2. Estimate normal returns using market model:
   ```
   R_it = α_i + β_i*R_mt + ε_it
   ```
   Estimate over estimation window (e.g., [-250, -11] days before event)
3. Calculate abnormal returns (AR):
   ```
   AR_it = R_it - (α_i + β_i*R_mt)
   ```
4. Aggregate across firms:
   ```
   AAR_t = (1/N) * Σ AR_it  (average abnormal return)
   CAR = Σ AAR_t  (cumulative abnormal return)
   ```
5. Test significance: t-test on CAR

**Stata**:
```stata
eventstudy return mktreturn, event_date(announce_date) window(-1,1) estimation_window(-250,-11)
```

**C. Regression Discontinuity Design (RDD)**

**Use When**: Policy/treatment has a cutoff (e.g., firms above $10M revenue get tax benefit)

**Idea**: Compare firms just above vs. just below cutoff (quasi-random assignment)

**Model**:
```
Y_i = β0 + β1*Treatment_i + β2*RunningVariable_i + β3*(Treatment × RunningVariable) + ε_i
```

**Stata**:
```stata
rdrobust roa revenue, c(10) all
```

---

## Phase 7: Writing the Academic Paper

### 7.1 Target Journal Selection

**Top Strategy & Organization Journals (FT50)**:

**Tier 1 (Top 3)**:
1. **Strategic Management Journal (SMJ)** - WileyBlackwell
   - Focus: Broad strategy topics, empirical & theoretical
   - Acceptance rate: ~8%
   - Average time to decision: 6-12 months

2. **Academy of Management Journal (AMJ)** - AOM
   - Focus: Management, organization theory, empirical
   - Acceptance rate: ~6%
   - Average time: 12-18 months

3. **Organization Science (OS)** - INFORMS
   - Focus: Organizational theory, micro-foundations, quantitative
   - Acceptance rate: ~8%
   - Average time: 6-12 months

**Tier 2**:
- **Administrative Science Quarterly (ASQ)** - Sage
- **Journal of Management (JOM)** - Sage
- **Journal of Management Studies (JMS)** - Wiley
- **Management Science** - INFORMS (some strategy papers)

**Field Journals**:
- **Global Strategy Journal** - Strategy & international business
- **Journal of International Business Studies (JIBS)** - International strategy
- **Research Policy** - Innovation strategy
- **Long Range Planning** - Corporate strategy, futures

**Regional Journals (Asia-Pacific Focus)**:
- **Asia Pacific Journal of Management** - Springer
- **Management and Organization Review** - Cambridge
- **日本経営学会誌 (Japan Academy of Management Journal)** - Japanese

### 7.2 Paper Structure (IMRaD Format)

**Standard Structure for Empirical Papers**:

1. **Title** (12-15 words)
   - Clear, specific, includes key variables
   - Example: "Dynamic Capabilities and Firm Performance: The Moderating Role of Environmental Dynamism"

2. **Abstract** (150-250 words)
   - Background (1-2 sentences)
   - Purpose (1 sentence)
   - Method (2-3 sentences)
   - Results (2-3 sentences)
   - Implications (1-2 sentences)

3. **Introduction** (4-5 pages)
   - Opening hook (real-world phenomenon)
   - Research problem & motivation
   - Theoretical puzzle / gap
   - Research question(s)
   - Key findings (preview)
   - Contributions (theoretical, empirical, practical)
   - Paper structure

4. **Literature Review & Hypotheses** (6-8 pages)
   - Review relevant theories
   - Synthesize prior empirical findings
   - Identify gaps
   - Develop hypotheses (2-5 hypotheses typical)

5. **Methods** (4-6 pages)
   - Research setting & sample
   - Data sources
   - Variable operationalization (DV, IVs, moderators, controls)
   - Analytical approach (regression specification)
   - Robustness checks planned

6. **Results** (6-8 pages)
   - Descriptive statistics (Table 1)
   - Correlations (Table 2)
   - Main regression results (Table 3)
   - Moderation effects (Table 4, Figure 1)
   - Robustness tests (Table 5)
   - Summary of findings

7. **Discussion** (5-7 pages)
   - Summary of findings
   - Theoretical contributions
   - Practical implications
   - Limitations
   - Future research directions

8. **Conclusion** (1-2 pages)
   - Recap key findings
   - Broader significance

9. **References** (30-80 references typical)

10. **Tables & Figures** (Appendix or embedded)

**Total Length**: 35-50 pages (double-spaced) for top journals

### 7.3 Results Presentation (Tables)

**Table 1: Descriptive Statistics**
```
Variable                    | N     | Mean  | SD    | Min   | Max
----------------------------|-------|-------|-------|-------|------
1. ROA                      | 5000  | 0.045 | 0.12  | -0.35 | 0.42
2. Log Assets               | 5000  | 7.85  | 1.95  | 3.2   | 14.2
3. Leverage                 | 5000  | 0.35  | 0.22  | 0     | 0.95
4. R&D Intensity            | 4100  | 0.032 | 0.05  | 0     | 0.25
5. Environmental Dynamism   | 5000  | 0.18  | 0.09  | 0.02  | 0.55
```

**Table 2: Correlation Matrix**
```
          | 1     | 2     | 3     | 4     | 5
----------|-------|-------|-------|-------|------
1. ROA    | 1.00  |       |       |       |
2. Size   | 0.15* | 1.00  |       |       |
3. Leverage| -0.22*| 0.35* | 1.00  |       |
4. R&D    | 0.08* | 0.12* | -0.15*| 1.00  |
5. Dynamism| 0.03 | -0.05*| 0.02  | 0.11* | 1.00

* p < 0.05
```

**Table 3: Regression Results**
```
DV: ROA                  | Model 1 | Model 2 | Model 3
-------------------------|---------|---------|----------
R&D Intensity            | 0.15*** | 0.12**  | 0.18***
                         | (0.04)  | (0.04)  | (0.05)
Environmental Dynamism   |         | 0.08*   | 0.10*
                         |         | (0.03)  | (0.04)
R&D × Dynamism           |         |         | 0.25**
                         |         |         | (0.09)
Log Assets               | 0.02*** | 0.02*** | 0.02***
                         | (0.005) | (0.005) | (0.005)
Leverage                 | -0.10***| -0.10***| -0.10***
                         | (0.02)  | (0.02)  | (0.02)
Industry FE              | Yes     | Yes     | Yes
Year FE                  | Yes     | Yes     | Yes
N                        | 5000    | 5000    | 5000
R²                       | 0.25    | 0.26    | 0.28
Adj R²                   | 0.24    | 0.25    | 0.27

Standard errors clustered at firm level in parentheses.
*** p < 0.001, ** p < 0.01, * p < 0.05
```

**Figure 1: Moderation Plot**
```
[Plot showing: X-axis = R&D Intensity, Y-axis = ROA, 
Two lines: High Dynamism (steeper slope), Low Dynamism (flatter slope)]
```

### 7.4 Writing Best Practices

**1. Theory-Driven, Not Data-Driven**:
- ❌ "We found that R&D has a positive effect, so we propose..."
- ✅ "Drawing on dynamic capabilities theory, we hypothesize that R&D enhances firm adaptability, leading to superior performance. Specifically, H1: ..."

**2. Clarity & Precision**:
- Avoid jargon without definition
- Use short sentences (< 25 words average)
- Active voice preferred: "We test..." not "It is tested..."

**3. Contribution Clarity**:
- **Theoretical**: "This study extends RBV by showing that..."
- **Empirical**: "We provide first large-scale evidence that..."
- **Practical**: "Managers should consider..."

**4. Honest Limitations**:
- Endogeneity concerns
- Sample limitations (country, industry, time period)
- Measurement issues
- Causal inference limitations

**5. Future Research (Not Vague)**:
- ❌ "Future research should examine this in other contexts."
- ✅ "Future research could examine whether these findings hold in service industries, where R&D may manifest differently (e.g., process innovation vs. product innovation)."

### 7.5 Common Rejection Reasons & How to Avoid

**Reason 1: Weak Theory**
- **Problem**: Hypotheses not grounded in theory
- **Solution**: Connect to established theories (RBV, TCE, etc.), explain mechanisms

**Reason 2: Incremental Contribution**
- **Problem**: "So what?" - findings are predictable
- **Solution**: Identify theoretical puzzles, unexpected findings, or boundary conditions

**Reason 3: Endogeneity Not Addressed**
- **Problem**: Reverse causality, omitted variables
- **Solution**: Use IV, propensity score matching, fixed effects, or acknowledge limitations

**Reason 4: Poorly Written**
- **Problem**: Unclear, verbose, grammatical errors
- **Solution**: Use writing support (Grammarly, copyeditor), get feedback from colleagues

**Reason 5: Weak Empirics**
- **Problem**: Small sample, inappropriate methods, no robustness checks
- **Solution**: Follow best practices, conduct robustness tests, report effect sizes

---

## Phase 8: Replication & Transparency

### 8.1 Replication Materials

**What to Archive**:
1. **Data**:
   - Raw data (if permitted by provider)
   - Cleaned, analysis-ready data
   - Data dictionary

2. **Code**:
   - Data cleaning scripts
   - Analysis scripts (Stata .do, R .R, Python .py)
   - README with step-by-step instructions

3. **Documentation**:
   - Data sources & access instructions
   - Sample selection decisions
   - Variable construction details

**Where to Archive**:
- **Dataverse** - https://dataverse.org/ (Harvard Dataverse)
- **OSF (Open Science Framework)** - https://osf.io/
- **Figshare** - https://figshare.com/
- **Zenodo** - https://zenodo.org/

**Licensing**:
- **Data**: CC BY 4.0 (if you have rights)
- **Code**: MIT License or CC0 (public domain)

### 8.2 Pre-Registration (Optional but Recommended)

**Purpose**: Increase credibility, reduce p-hacking concerns

**Platforms**:
- **AsPredicted** - https://aspredicted.org/
- **OSF Registries** - https://osf.io/registries

**What to Pre-Register**:
- Research question(s) & hypotheses
- Sample selection criteria
- Variable definitions
- Analytical plan (regressions, tests)
- Planned robustness checks

**When**: Before data collection or before analyzing data (if data already collected)

---

## Integration with Existing Skills

This skill integrates seamlessly with:

### Related Skills in Your Workspace:
1. **research-data-collection**: General research workflow management (all fields)
2. **corporate-research-data-hub**: Corporate finance & governance data (specialized)
3. **academic-paper-creation**: Japanese academic paper writing (30,000 characters)

### Public Skills:
- **docx, pptx, xlsx**: Document creation for reports, presentations, data analysis
- **pdf**: Extracting data from PDF reports
- **csv-data-summarizer-claude-skill**: Automated CSV analysis
- **scientific-databases** (K-Dense-AI): Access to scientific databases (if relevant for interdisciplinary work)

**Usage Example**:
```
"Use strategic-organizational-research-hub to design my data collection plan for 
a study on alliance formation strategies in the semiconductor industry. 
Then use docx skill to create a detailed research proposal."
```

---

## Common Workflows

### Workflow 1: Starting a New Research Project

**User**: "I want to study how board gender diversity affects firm innovation in Japanese manufacturing firms, 2010-2023."

**Claude's Response (Using This Skill)**:
1. **Phase 1: Theoretical Framework**
   - Identify relevant theories (Resource Dependence Theory, Human Capital Theory)
   - Develop hypotheses (e.g., H1: Board gender diversity is positively associated with patent output)
   - Identify moderators (firm size, industry R&D intensity)

2. **Phase 2: Research Design**
   - Sample: Japanese listed manufacturing firms (SIC 20-39), 2010-2023
   - Required variables: Board composition, patent counts, financials, controls

3. **Phase 3: Data Sources**
   - **Board data**: EDINET (有価証券報告書) - free
   - **Financial data**: NEEDS-FinancialQUEST (if accessible) or EDINET
   - **Patent data**: USPTO PatentsView (free) - Japanese firms patenting in U.S.
   - **Industry data**: OECD STAN database (free)

4. **Phase 4: Data Collection Plan**
   - Download EDINET data (annual reports, 役員の状況)
   - Extract board composition (male/female directors)
   - Download USPTO patents assigned to Japanese firms
   - Download financials from EDINET
   - Match firms using company names (fuzzy matching)

5. **Phase 5: Analysis Plan**
   - DV: Patent count (Poisson or negative binomial regression)
   - IV: % female directors
   - Controls: Firm size, age, R&D spending, leverage, industry, year FE
   - Moderators: Firm size (interaction term)

6. **Phase 6: Expected Timeline**
   - Data collection: 3-4 weeks
   - Data cleaning: 2 weeks
   - Analysis: 1-2 weeks
   - Writing: 4-6 weeks
   - Total: 10-14 weeks

**Output**: Detailed research proposal document (using docx skill)

### Workflow 2: Replicating & Extending a Published Study

**User**: "I want to replicate Barney's (1991) RBV study using recent data and extend it to emerging markets."

**Claude's Response**:
1. **Literature Review**: Summarize Barney (1991) and subsequent tests
2. **Data Equivalence**: Identify how to measure VRIN resources with available data
3. **Sample**: Select emerging market data sources (e.g., Orbis for Brazil, China, India)
4. **Extension**: Add institutional variables (World Bank Governance Indicators)
5. **Analysis**: Panel regressions with fixed effects
6. **Contribution**: "We extend RBV to emerging markets and show that institutional quality moderates resource-performance link"

### Workflow 3: Conducting an Event Study

**User**: "Measure stock market reaction to CEO succession announcements in U.S. tech firms, 2015-2023."

**Claude's Response**:
1. **Event Identification**: Search SDC, Factiva, or company press releases for CEO succession events
2. **Stock Price Data**: CRSP (via WRDS) - daily returns
3. **Market Returns**: CRSP value-weighted index
4. **Estimation Window**: [-250, -11] days
5. **Event Window**: [-1, +1] days
6. **Calculate**: Abnormal returns (AR), cumulative abnormal returns (CAR)
7. **Test**: t-test on CAR, cross-sectional regression (AR vs. firm characteristics)

---

## Best Practices Summary

1. **Start with Theory**: Always ground hypotheses in established theories
2. **Plan Before Collecting**: Write a detailed data collection plan before accessing data
3. **Document Everything**: Data sources, dates, transformations, decisions
4. **Test Early**: Pilot data collection on 10-20 firms before full sample
5. **Quality Over Quantity**: 1,000 high-quality observations > 10,000 low-quality
6. **Robustness is Key**: Run multiple specifications, check sensitivity
7. **Transparent Reporting**: Acknowledge limitations, provide replication materials
8. **Iterate**: Get feedback early and often from advisors, colleagues
9. **Read Widely**: Study published papers in target journals for standards
10. **Time Management**: Allocate 30-40% of research time to data collection

---

## Troubleshooting Common Issues

### Issue: Low R² in Regression
**Diagnosis**: 
- Normal in strategy research (firm performance has many determinants)
- R² = 0.10-0.30 is typical

**Action**: 
- Focus on significance and effect sizes, not just R²
- Report adjusted R²
- If R² < 0.05, reconsider model specification

### Issue: Non-Significant Results
**Diagnosis**: 
- Insufficient sample size (low statistical power)
- Measurement error
- Theory may be wrong (which is a valid finding!)

**Action**: 
- Conduct post-hoc power analysis
- Check variable operationalization
- Consider publishing null results (some journals accept)

### Issue: Multicollinearity (VIF > 10)
**Diagnosis**: 
- High correlation between predictors
- Common with firm size, sales, assets

**Action**: 
- Drop one of the correlated variables
- Use principal component analysis (PCA)
- Mean-center variables before creating interaction terms

### Issue: Missing Data for Key Variable
**Diagnosis**: 
- Variable not reported by all firms (e.g., R&D)

**Action**: 
- Report % missing: "R&D data available for 78% of sample"
- Use indicator method (dummy for missing + impute 0)
- Conduct sensitivity analysis (compare full sample vs. R&D-reporting sample)

### Issue: Endogeneity Concerns
**Diagnosis**: 
- Reverse causality, omitted variables

**Action**: 
1. **Lagged IVs**: Use X(t-1) to predict Y(t)
2. **Instrumental variables**: Find exogenous instrument
3. **Fixed effects**: Control for unobserved firm heterogeneity
4. **Heckman selection**: If sample selection bias
5. **Acknowledge limitation**: If no solution available

### Issue: Reviewer Requests "Additional Robustness Checks"
**Action**:
- **Alternative DV**: Use different performance measure (ROE instead of ROA)
- **Alternative sample**: Exclude certain industries, firm sizes, years
- **Alternative specification**: Quadratic terms, logged variables
- **Subsample analysis**: Split by industry, country, time period
- **Propensity score matching**: If selection concerns

---

## Version History

**v1.0** (2025-10-31)
- Initial release
- Comprehensive integration of research-data-collection, corporate-research-data-hub, academic-paper-creation
- Expanded data sources (70+ databases, free & paid)
- Strategy-specific theoretical frameworks (10+ theories)
- Statistical analysis guide (OLS, panel, DiD, IV, survival, event studies)
- Paper writing for top journals (SMJ, AMJ, OS)
- Replication & transparency guidelines
- Asia-Pacific data sources (Japan, China, Korea, Taiwan, India)
- Zero-budget research strategies

---

## Citation

If this skill significantly aids your research, consider citing it:

```
Data collection, theoretical framework development, and statistical analysis 
followed systematic protocols for business strategy and organizational strategy 
empirical research (strategic-organizational-research-hub skill v1.0), 
ensuring reproducibility and methodological rigor throughout the research process.
```

---

## License & Disclaimer

This skill is a research planning and execution tool. Researchers remain responsible for:
1. Complying with all data provider terms of service
2. Obtaining necessary institutional approvals (IRB, ethics review)
3. Properly citing data sources and prior research
4. Ensuring ethical use of data and protection of human subjects
5. Verifying data accuracy and appropriateness for their research

---

**Ready to start your strategic management or organizational strategy research?**

Describe your research question, and I will guide you through:
1. Developing theoretical framework & hypotheses
2. Designing research (sample, variables, methods)
3. Identifying optimal data sources (free or paid)
4. Creating data collection strategy
5. Planning statistical analysis
6. Structuring your academic paper for target journals
7. Preparing replication materials

**Example starting prompts:**
- "I'm studying the effect of CEO characteristics on firm internationalization strategy in Asian firms."
- "Help me design a study on the relationship between alliance portfolio diversity and innovation performance."
- "I want to conduct an event study on M&A announcements in the pharmaceutical industry."
- "I need to replicate Porter's five forces analysis using modern data and extend it to digital platforms."
- "What free data sources can I use for a study on board composition and firm ESG performance in Japan?"