---
name: thinking-toolkit
description: |
  思考支援・理論構築・アイデア発展のための統合ツールキット。以下の機能を包括：
  (1) RecursiveThink - 6エージェント協働による多視点分析
  (2) Theory Building - 弁証法的推論、競合仮説、ソクラテス式問答
  (3) Context Engineering - 4大戦略（Writing/Selecting/Compressing/Isolating）による文脈最適化
  (4) Brainstorming - アイデアからデザインへの協調的開発
  トリガー：「深く考えて」「多角的分析」「理論構築」「仮説生成」「ブレインストーミング」「Context Engineering」
---

# Thinking Toolkit - 思考支援統合ツールキット

## 概要

複雑な問題の分析、理論構築、アイデア発展を支援する統合思考ツールキットです。6つの専門思考エージェントによる多視点分析、弁証法的理論構築、文脈知性システム、協調的ブレインストーミングを提供します。

**統合元スキル**：
- recursive-think（6エージェント協働分析）
- theory-building（理論構築支援）
- context-engineering（文脈工学）← 大幅拡充
- brainstorming（アイデア開発）

## When to Use This Skill

以下の場合にこのスキルを使用：

- 複雑な問題の多角的分析
- 理論構築・仮説生成
- 批判的思考・バイアス防止
- アイデアの発展・デザイン化
- 研究クエスチョンの精緻化

**トリガーキーワード**：
- 「RecursiveThink」「深く考えて」「多角的に分析」
- 「理論構築」「仮説生成」「Theory Building」
- 「Context Engineering」「文脈工学」「コンテキスト最適化」
- 「ブレインストーミング」「アイデア出し」

---

# Part 1: RecursiveThink - 多視点分析システム

## 1.1 概要

6つの専門思考エージェントが協働し、単一視点の限界を超えた深い洞察を生み出します。

### 6つの思考エージェント

| エージェント | 特性 | 役割 |
|--------------|------|------|
| 体系的分析者 | 精密、詳細志向 | 問題の分解と構造化 |
| 創造的探索者 | 発散的思考、革新志向 | 新視点と非従来的アプローチ |
| 批判的評価者 | 懐疑的、検証志向 | 弱点特定と前提への挑戦 |
| 統合的総合者 | 全体論的、関係性重視 | 多様な視点の統合 |
| 実践的戦略家 | 実用的、結果志向 | 理論から実践への橋渡し |
| 引用検証専門家 | 精確、形式重視 | 情報源の検証と管理 |

## 1.2 4段階思考プロセス

### 第0段階：原文忠実分析と構造化
```
担当：体系的分析者 + 引用検証専門家

実行内容：
- 資料の完全な理解と構造化
- 主要論点の抽出と分類
- 事実と主張の分離
- 引用と出典の初期検証

成果物：
- 構造化された資料マップ
- 主要概念の定義リスト
```

### 第1段階：批判的分析と論点抽出
```
担当：批判的評価者 + 創造的探索者

実行内容：
- 前提条件と暗黙の仮定の特定
- 論理的欠陥と矛盾の検出
- 代替的解釈の探索
- 深堀りすべき論点の抽出

成果物：
- 批判的検討レポート
- 深堀り論点リスト
```

### 第2段階：多角的調査と証拠収集
```
担当：実践的戦略家 + 体系的分析者 + 引用検証専門家

実行内容：
- 論点ごとの情報源探索
- 信頼性の高いエビデンス収集
- 複数視点からのデータ統合
- 引用の厳格な検証

成果物：
- エビデンスマトリックス
- 検証済み引用リスト
```

### 第3段階：統合的考察と実装提案
```
担当：統合的総合者 + 実践的戦略家 + 創造的探索者

実行内容：
- 多様な洞察の統合
- 一貫したフレームワークの構築
- 実践的応用の提案
- 残された課題の明示

成果物：
- 統合レポート
- 実装ロードマップ
```

## 1.3 思考劣化防止メカニズム

### 反論生成プロトコル
```
各段階の完了時に実行：
1. 現在のコンセンサスの明示化
2. 意図的な反論の生成（批判的評価者）
3. 反論の妥当性評価
4. 分析への統合または棄却
```

### 多様性強制メカニズム
```
検出条件：
- 同じ結論が3回以上繰り返される
- 単一視点からの分析が2段階連続
- 特定エージェントの発言が70%を超える

是正措置：
- 発言の少ないエージェントに強制発言権付与
- 意図的な視点シフトの実施
```

## 1.4 起動コマンド

```
RecursiveThink起動

分析対象：[資料名または問題記述]
問題タイプ：[技術的/社会的/歴史的/学際的]
重点視点：[オプション：特に重視したい視点]
出力形式：[統合レポート/段階別詳細/簡易版]
```

---

# Part 2: Theory Building - 理論構築支援

## 2.1 概要

戦略経営論・組織論のための高度な理論構築支援。弁証法的推論、競合仮説生成、ソクラテス式問答を統合。

## 2.2 競合仮説生成

### プロセス

**Step 1: 現象の明確化**
```
- 時間的・空間的境界
- 分析単位
- 主要特性
```

**Step 2: 5-7の競合説明を生成**
```
理論的レンズ：
- Resource-Based View (RBV)
- Transaction Cost Economics (TCE)
- Institutional Theory
- Dynamic Capabilities
- Social Network Theory
- Behavioral Theory
```

**Step 3: 各仮説の詳細化**
```
H1: [理論名] - [核心メカニズム]

因果メカニズム：
X → [中間変数] → Y

主要変数：
- 独立変数：[具体的変数]
- 媒介変数：[媒介変数]
- 従属変数：[従属変数]
- 調整変数：[該当する場合]

境界条件：
- 時間的：[適用期間]
- 文脈的：[適用される状況]

反証条件：
- もし[条件]であれば、この仮説は棄却
```

## 2.3 ソクラテス式問答（Feynman強化版）

### 質問階層

```
Level 1: 記述的
「何が起きたか？」「出来事の順序は？」

Level 2: 説明的
「なぜ起きたか？」「代替説明は？」

Level 3: メカニズム的 ← 重要
「段階的プロセスは？」「各中間段階で何が起きる？」

Level 4: 条件的
「どの条件で機能する？」「失敗するのはいつ？」

Level 5: 理論的
「既存理論とどう関係？」「理論的新規性は？」

Level 6: Feynman基盤層 ← パラダイムシフト
「そのメカニズムがなぜ存在する？」
「その前提が誤りなら何が残る？」
「基盤となる原理は何か？」
```

### 5層Why Chainの例

```
主張：「ネットワーク効果 → プラットフォーム支配」

Layer 1: なぜネットワーク効果が支配を生む？
→ ユーザー増加 → 価値増加 → さらにユーザー増加（正のフィードバック）

Layer 2: なぜ正のフィードバックが支配につながる？
→ 先行者が過半数を獲得、追随者は追いつけない

Layer 3: なぜ追随者は追いつけない？
→ スイッチングコストがユーザーをロックイン

Layer 4: なぜスイッチングコストがマルチホーミングを防ぐ？
→ 認知的限界により単一プラットフォームを選好

Layer 5: その前提は？
→ ユーザーは価値の受動的受け手

💡 パラダイムシフト：
もしユーザーがプラットフォーム間で積極的に価値創造するなら？
→ マルチホーミングが戦略的に（TikTok + Instagramクリエイター）
→ ネットワーク効果が分散、集中しない
→ プラットフォーム支配はユーザーの受動性に条件付き
```

## 2.4 Einstein式境界テスト

### 極限思考実験

```
Test A: ゼロ極限
「[変数]がゼロに近づくと？」
→ 摩擦消失時に何が残るか明らかに

Test B: 無限極限
「[変数]が無限大に近づくと？」
→ 無制限リソース時の制約が明らかに

Test C: 符号反転
「[変数]の方向が逆転したら？」
→ 非対称メカニズムが明らかに

Test D: 時間反転
「理想的未来から逆算すると？」
→ 経路依存性と不可逆性が明らかに
```

## 2.5 バイアス検出・軽減

### 監視対象バイアス

| バイアス | 検出サイン | 対策 |
|----------|------------|------|
| 確証バイアス | 支持証拠のみ引用 | 反証証拠の体系的検索 |
| 利用可能性ヒューリスティック | 最近/顕著な事例に依存 | 系統的サンプリング |
| アンカリング | 初期理論から離れない | 代替理論からの再スタート |
| HARKing | 結果後の仮説変更 | 事前/事後仮説の明確区分 |
| 理論誘導盲目 | 不整合データの無視 | 異常値の積極的探索 |

### バイアス検出時の対応
```
🚨 [バイアス名] Alert

問題：[具体的な問題点]
理由：[なぜ問題か]
軽減策：[具体的な対処法]
例：[より良い実践の例]
```

---

# Part 3: Context Engineering - 文脈工学

## 3.1 概要

### Context Engineeringとは

Andrej Karpathyによる定義に基づく：
> "Context Engineering is the delicate art and science of filling the context window with just the right information for the next step."
> （文脈工学とは、次のステップに必要な適切な情報でコンテキストウィンドウを満たす繊細な技術と科学である）

### LLMのオペレーティングシステム・アナロジー

```
LLM = CPU（処理エンジン）
Context Window = RAM（作業記憶）
├── 容量制限あり（通常200Kトークン）
├── 情報の取捨選択が必要
└── OS（オペレーティングシステム）のようにRAMを管理する
    → これがContext Engineeringの役割
```

### なぜエージェントで特に重要か

エージェントは以下の特性により、大量のコンテキストを消費する：

1. **長期タスク処理**：複数ターンにわたる会話・作業
2. **ツール呼び出し**：ツールフィードバックの蓄積
3. **複雑性**：高度なタスクほど多くの文脈が必要

```
ターン1: ツール呼び出し → フィードバック蓄積
ターン2: ツール呼び出し → さらに蓄積
...
ターンN: コンテキスト肥大化 → 性能劣化リスク
```

### Context障害モード（Drew Brunによる分類）

| 障害モード | 説明 | 影響 |
|------------|------|------|
| Context Poisoning | 誤情報・幻覚の注入 | 後続推論の汚染 |
| Context Distraction | 無関係情報による注意散漫 | 重要情報の見落とし |
| Context Curation失敗 | 不適切な情報選択 | タスク遂行能力低下 |
| Context Clash | 矛盾する情報の共存 | 一貫性のない出力 |

---

## 3.2 Context Engineering 4大戦略

### 概念図

```
┌─────────────────────────────────────────────────────────────────┐
│                    Context Engineering                          │
├──────────────────┬──────────────────┬──────────────────┬───────┤
│  1. Writing      │  2. Selecting    │  3. Compressing  │ 4. Isolating │
│  文脈の記録       │  文脈の選択       │  文脈の圧縮      │ 文脈の分離   │
├──────────────────┼──────────────────┼──────────────────┼───────┤
│ ・Scratch Pad    │ ・Tool Selection │ ・Summarization  │ ・Multi-Agent│
│ ・Memory         │ ・RAG/Knowledge  │ ・Trimming       │ ・Sandbox    │
│ （セッション内/間）│ ・Memory Recall  │ ・Pruning        │ ・State分離  │
└──────────────────┴──────────────────┴──────────────────┴───────┘
```

---

## 3.3 戦略1: Writing Context（文脈の記録）

### 目的
コンテキストウィンドウの外部に情報を保存し、エージェントがタスク遂行を支援する

### 3.3.1 Scratch Pad（スクラッチパッド）

**定義**：タスク実行中に永続化するメモ・計画

```
用途：
├── 計画の記録と参照
├── 中間結果の保存
├── 進捗状況の追跡
└── 重要な発見・洞察のメモ

実装パターン：
├── ファイルへの書き出し
├── State Objectへの保存
└── 構造化データモデルへの格納
```

**研究タスクでの活用例**：

```markdown
## Research Scratch Pad

### 現在の計画
1. 先行研究レビュー ✓
2. 理論的フレームワーク構築 [進行中]
3. 仮説の形式化 [待機]

### 重要な発見
- Smith (2020): ネットワーク効果は30%のケースで逆効果
- 境界条件: 市場成熟度が調整変数として機能

### 未解決の疑問
- なぜアジア市場ではパターンが異なるのか？
- 時間遅れ効果の測定方法は？
```

### 3.3.2 Memory（記憶）

**定義**：複数セッションにわたって保持する情報

```
記憶の3類型（認知科学に基づく）：

1. 意味記憶（Semantic Memory）
   └── 事実、定義、概念的知識
   └── 例：「RBVは企業の競争優位を資源の観点から説明する理論」

2. エピソード記憶（Episodic Memory）
   └── 過去の経験、事例、Few-shot例
   └── 例：「前回のレビューでA教授から方法論の指摘を受けた」

3. 手続き記憶（Procedural Memory）
   └── 手順、ルール、スタイルガイドライン
   └── 例：「この論文誌では能動態を使用し、1人称を避ける」
```

**記憶更新プロトコル**：

```
新規コンテキスト入力
        ↓
既存記憶との照合
        ↓
    ┌───┴───┐
  矛盾あり  矛盾なし
    ↓         ↓
  解消・更新   統合・追加
    ↓         ↓
    └────┬────┘
         ↓
   記憶ストアに保存
```

---

## 3.4 戦略2: Selecting Context（文脈の選択）

### 目的
タスク遂行に必要な情報を適切なタイミングで選択的にコンテキストウィンドウに取り込む

### 3.4.1 Tool Selection（ツール選択）

**問題**：ツール数が30を超えると性能劣化、100を超えると完全失敗

```
解決策：ツール説明文への埋め込みベース類似検索

プロセス：
1. 全ツールの説明文をベクトル化
2. タスク/クエリをベクトル化
3. 類似度に基づき上位N件を選択
4. 選択されたツールのみをコンテキストに含める

効果：
├── コンテキスト使用量の削減
├── 関連ツールへの集中
└── 精度向上（不要ツールによる混乱防止）
```

### 3.4.2 Knowledge Retrieval（知識検索：RAG）

**コードエージェントに学ぶ高度なRAG技法**（Windsurf CEOの知見）：

```
非自明な検索戦略：

1. セマンティックチャンキング
   └── 意味的に有意義な境界でコード/文書を分割
   └── ランダムブロック分割は避ける

2. 複合検索アプローチ
   ├── 埋め込みベース類似検索
   ├── キーワード/グラフ検索
   └── LLMベースのリランキング

3. 文脈考慮型検索
   └── 現在のタスク・過去の履歴を考慮
   └── 単純な質問マッチングを超える
```

**研究文脈での適用**：

```
文献検索の層別アプローチ：

Layer 1: キーワードベース
└── 具体的な著者名、理論名、年度

Layer 2: セマンティック検索
└── 概念的類似性による関連論文発見

Layer 3: 引用ネットワーク
└── 被引用・引用関係による発見

Layer 4: LLMリランキング
└── 研究目的との関連度評価
```

### 3.4.3 Memory Recall（記憶の呼び出し）

**呼び出しトリガー**：

```
手続き記憶：
├── セッション開始時に自動ロード
└── ルールファイル、スタイルガイドの読み込み

意味記憶：
├── タスク関連キーワードで検索
└── 必要な事実・定義をオンデマンド取得

エピソード記憶：
├── 類似タスクパターンで検索
└── 過去の成功/失敗事例から学習
```

---

## 3.5 戦略3: Compressing Context（文脈の圧縮）

### 目的
タスク遂行に必要なトークンのみを保持し、コンテキスト肥大化を防ぐ

### 3.5.1 Summarization（要約）

**適用タイミング**：

```
1. コンテキスト上限接近時（95%閾値など）
   └── 全会話履歴の自動圧縮

2. 完了セクション単位
   └── 終了したタスク部分のみ要約
   └── 進行中の部分は詳細を保持

3. エージェント間インターフェース
   └── サブエージェントへの引き継ぎ時に圧縮
   └── 必要情報のみを次段階に渡す
```

**要約テンプレート**：

```markdown
## 完了セクション要約

### 実行内容
[何を行ったかの簡潔な記述]

### 主要な成果
- [成果1]
- [成果2]

### 残された課題
- [課題1]

### 次ステップへの引き継ぎ事項
[後続処理に必要な情報のみ]
```

### 3.5.2 Trimming（トリミング）

**ヒューリスティックベース**：

```
戦略：
├── 直近Nメッセージのみ保持
├── 古いツール出力を削除
├── 重複情報の除去
└── 低関連度コンテンツの剪定
```

**学習ベース（LLM活用）**：

```
プロセス：
1. 現在のタスク目標を明確化
2. 各コンテキスト要素の関連度をLLMで評価
3. 閾値以下の要素を除去
4. 重要情報の見落としチェック
```

### 3.5.3 ツール出力の後処理

```
トークン重量級ツール出力への対処：

1. 検出
   └── 出力トークン数の監視
   └── 閾値超過時にアラート

2. 処理
   ├── 構造化抽出（必要フィールドのみ）
   ├── 要約生成
   └── 参照ポインタ化（本体は外部保存）

3. 再構成
   └── コンパクトな形式でコンテキストに戻す
```

---

## 3.6 戦略4: Isolating Context（文脈の分離）

### 目的
コンテキストを分割し、エージェントが処理可能な総トークン数を拡大する

### 3.6.1 Multi-Agent Architecture（マルチエージェント構成）

```
利点：
├── 各エージェントが独立したコンテキストウィンドウを持つ
├── 並列処理による探索範囲の拡大
├── 専門化による精度向上
└── 総処理可能トークン数の拡大（N × ウィンドウサイズ）

パターン：
1. Supervisor型
   └── 監督エージェントがサブエージェントを調整

2. Swarm型
   └── 関心事の分離に基づく協調

3. Researcher型
   └── リードエージェント + 並列サブエージェント
   └── 各サブエージェントが独立して調査
```

**研究タスクでの活用**：

```
リード研究者
├── 全体計画の策定
├── サブタスクの割り当て
└── 結果の統合

サブエージェント1: 文献レビュー担当
├── 独自のコンテキストで文献探索
└── 要約をリードに報告

サブエージェント2: データ分析担当
├── 独自のコンテキストで分析実行
└── 結果をリードに報告

サブエージェント3: 理論構築担当
├── 独自のコンテキストで理論検討
└── フレームワークをリードに報告
```

### 3.6.2 Sandbox/Environment（サンドボックス環境）

**コードエージェントの手法**（Hugging Face Open Deep Research）：

```
仕組み：
1. LLMがコード生成
2. サンドボックスで実行
3. 環境が状態を永続化
4. 選択的に結果のみLLMに返却

利点：
├── トークン重量級オブジェクト（画像、音声等）の隔離
├── 複数ターンにわたる状態の保持
├── LLMへの情報選択的フィードバック
└── コンテキスト汚染の防止
```

### 3.6.3 State Object分離

```
構造化状態オブジェクトの設計：

class ResearchState:
    # 常時公開（各ステップでLLMに露出）
    current_task: str
    messages: List[Message]

    # 選択的公開（必要時のみ）
    literature_cache: Dict
    intermediate_results: List

    # 終盤のみ公開
    final_synthesis: str

    # 外部永続化（コンテキスト外）
    full_document_store: ExternalStorage
```

---

## 3.7 Context Intelligence起動プロトコル

### 標準起動コマンド

```
Context Engineering起動

タスク: [タスクの説明]
タスク複雑度: [単純/中程度/複雑/超複雑]
予想ターン数: [少数(1-5)/中程度(5-15)/多数(15+)]
ツール使用: [なし/軽度/重度]
セッション要件: [単発/継続/長期プロジェクト]
```

### 複雑度別戦略選択マトリックス

```
┌──────────────┬─────────────┬─────────────┬─────────────┬─────────────┐
│ 複雑度        │ Writing     │ Selecting   │ Compressing │ Isolating   │
├──────────────┼─────────────┼─────────────┼─────────────┼─────────────┤
│ 単純          │ 不要        │ 基本検索    │ 不要        │ 不要        │
│ 中程度        │ Scratch Pad │ 選択的RAG   │ 軽度Trim    │ 不要        │
│ 複雑          │ 全機能      │ 高度RAG     │ 要約+Trim   │ State分離   │
│ 超複雑        │ 全機能+Memory│ 全検索戦略  │ 積極的圧縮  │ Multi-Agent │
└──────────────┴─────────────┴─────────────┴─────────────┴─────────────┘
```

### Context健全性監視

```
監視指標：

1. コンテキスト使用率
   └── [現在トークン数 / 上限] × 100%
   └── 閾値：80%で警告、95%で圧縮開始

2. 情報密度
   └── 有用情報トークン / 総トークン
   └── 低下時はTrimming実行

3. 一貫性スコア
   └── 矛盾情報の検出
   └── Context Clash発生時に解消プロトコル発動

4. 鮮度指標
   └── 情報の最終更新からの経過
   └── 古い情報は優先的に圧縮対象
```

---

## 3.8 研究タスク特化プロトコル

### 3.8.1 文献レビュープロトコル

```
Phase 1: 広範検索（Selecting重視）
├── キーワード検索
├── セマンティック検索
└── 引用ネットワーク探索

Phase 2: 情報蓄積（Writing重視）
├── 各文献の要約をScratch Padに
├── 重要引用の構造化保存
└── 理論的ギャップの記録

Phase 3: 圧縮統合（Compressing重視）
├── 冗長な引用の統合
├── 主要論点への集約
└── 文献マトリックスの構築

Phase 4: レビュー執筆（Isolating検討）
├── サブトピック別に分離可能
└── 各セクションを独立処理
```

### 3.8.2 理論構築プロトコル

```
理論開発段階別のContext戦略：

1. 現象記述段階
   └── Writing: 観察・事例の詳細記録
   └── Selecting: 広範な経験的証拠

2. 概念化段階
   └── Compressing: 具体例から抽象概念へ
   └── Memory: 関連理論の呼び出し

3. 命題構築段階
   └── Isolating: 各因果経路を分離検討
   └── Writing: 境界条件の明示的記録

4. 理論統合段階
   └── Selecting: 全中間成果を収集
   └── Compressing: 統一フレームワークへ圧縮
```

### 3.8.3 論文執筆プロトコル

```
セクション別Context管理：

Abstract
└── 全体要約をScratch Padから生成

Introduction
├── Memory: 先行研究の重要知見
└── Scratch Pad: 研究ギャップと貢献

Literature Review
├── 蓄積した文献要約を選択的ロード
└── 大量文献はマルチエージェント処理

Theory & Hypotheses
├── 理論構築Scratch Padから選択
└── 仮説の形式化と境界条件

Method
├── 手続き記憶からテンプレート呼び出し
└── データ記述は必要最小限

Results
├── 分析出力の要約版をロード
└── 詳細表は外部参照

Discussion
├── 複数セクションの圧縮統合
└── Memory: 理論的インプリケーション
```

---

## 3.9 障害対応プロトコル

### Context Poisoning対応

```
検出：
├── 事実と矛盾する情報の出現
├── 以前の正確な情報との不整合
└── 信頼できないソースからの情報混入

対応：
1. 汚染源の特定
2. 汚染されたコンテキスト部分の隔離
3. 信頼できるソースからの再取得
4. 修正情報でのコンテキスト再構築
```

### Context Distraction対応

```
検出：
├── タスクから逸脱した情報の蓄積
├── 関連度スコアの低下
└── 処理効率の低下

対応：
1. タスク目標の再確認
2. 関連度評価の実行
3. 低関連情報のTrimming
4. フォーカスの再設定
```

### Context Overflow対応

```
予防：
├── 定期的な使用率監視
├── 閾値に基づく早期警告
└── 漸進的な圧縮の実行

緊急対応：
1. 即座のCompact実行
2. 非本質的コンテキストの削除
3. 継続に必要な情報のみ保持
4. 詳細情報は外部永続化
```

---

## 3.10 実装チェックリスト

### セッション開始時

```
[ ] タスク複雑度の評価
[ ] 適切なContext戦略の選択
[ ] Scratch Padの初期化
[ ] 関連Memoryのロード
[ ] 必要ツールの事前選択
```

### セッション中

```
[ ] 重要な発見のScratch Pad記録
[ ] コンテキスト使用率の監視
[ ] 適時のCompressing実行
[ ] 矛盾情報のチェック
[ ] 必要に応じたIsolating判断
```

### セッション終了時

```
[ ] 長期保存すべきMemoryの特定
[ ] セッション要約の生成
[ ] 次回セッションへの引き継ぎ情報整理
[ ] 一時データのクリーンアップ
```

---

# Part 4: Brainstorming - アイデア開発

## 4.1 概要

アイデアを完全なデザイン・仕様に発展させるための協調的対話プロセス。

## 4.2 プロセス

### Phase 1: アイデア理解
```
1. 現在のプロジェクト状態を確認
2. 質問を1つずつ（一度に複数質問しない）
3. 選択肢形式の質問を優先
4. 目的、制約、成功基準に焦点
```

### Phase 2: アプローチ探索
```
1. 2-3の異なるアプローチをトレードオフと共に提案
2. 推奨案を理由と共に先行提示
3. 対話的に選択肢を絞り込み
```

### Phase 3: デザイン提示
```
1. 理解が十分と判断したらデザインを提示
2. 200-300語のセクションに分割
3. 各セクション後に確認
4. カバー項目：アーキテクチャ、コンポーネント、データフロー、エラー処理、テスト
```

## 4.3 原則

```
- 一度に1つの質問
- 可能な限り選択肢形式
- YAGNI（不要な機能は徹底排除）
- 代替案を常に探索
- 漸進的検証
- 柔軟に立ち戻り
```

## 4.4 起動コマンド

```
Brainstorming起動

アイデア: [アイデアの概要]
目的: [達成したいこと]
制約: [技術的制約、時間、予算等]
既存状態: [現在のプロジェクト状態]
```

---

# Part 5: 統合ワークフロー

## 5.1 問題タイプ別推奨アプローチ

```
問題タイプ判定ツリー：

メカニズムが明確？
├─ NO → Feynman 5-Why Chain を適用
│         基盤前提が明らかになるまで分解
│
└─ YES → 境界条件は特定されている？
          ├─ NO → Einstein極限テストを適用
          │         極限ケースで理論をストレステスト
          │
          └─ YES → 理論は新規性がある？
                    ├─ NO → クロスドメイン統合を適用
                    │         他分野から概念を輸入
                    │
                    └─ YES → 理論完成
                              実証テストへ進む
```

## 5.2 組み合わせ戦略

### 漸進的理論開発
```
1. 標準機能（競合仮説、弁証法）から開始
2. 行き詰まったらFeynman 5-Whyを適用
```

### パラダイムシフト研究
```
1. Feynman 5-Why（前提の露出）
2. Einstein極限テスト（境界テスト）
3. クロスドメイン統合（新規メカニズム）
4. 弁証法的統合（総合）
```

### 理論精緻化
```
1. Einstein極限テスト（理論が破綻する箇所を発見）
2. Feynman 5-Why（なぜ破綻するか理解）
3. 境界条件の特定（限界を文書化）
```

---

# Part 6: 品質基準

## 理論的厳密性チェックリスト

```
[ ] 構成概念妥当性
    - 定義が明確で独自か
    - 既存構成概念と重複していないか
    - 操作化可能か

[ ] 因果メカニズム
    - 段階的プロセスが特定されているか
    - ブラックボックスがないか
    - 代替メカニズムが検討されているか

[ ] 境界条件
    - 時間的範囲が明確か
    - 文脈的限界が特定されているか
    - スコープ声明が明示的か

[ ] 反証可能性
    - テスト可能な予測があるか
    - 反証条件が述べられているか
    - 競合理論と区別可能か

[ ] 理論的貢献
    - 既存理論をどう挑戦/拡張するか
    - 概念的に何が新規か
    - 新しい予測が生まれるか
```

---

## 連携スキル

| スキル名 | 役割 |
|----------|------|
| academic-research-suite | 文献レビュー・論文執筆・引用管理 |
| strategic-research-platform | 実証研究・統計分析への橋渡し |
| research-data-hub | データ収集・品質管理 |
| document-design-suite | 結果の可視化・図表作成 |
| content-extractor | 分析対象コンテンツの取得 |

---

## HumanLayer Context Engineering Integration

本セクションは、HumanLayerの12 Factor AgentsおよびACE-FCA（Advanced Context Engineering for Coding Agents）に基づく、コンテキストウィンドウ最適化と信頼性向上のための実践的ガイドラインを提供する。

### コンテキスト予算管理

**使用率目標**: 40-60%

**「ダムゾーン」問題**: HumanLayerの研究により、コンテキストウィンドウの中央40-60%で想起・推論が劣化することが判明。重要情報はウィンドウの先頭または末尾に配置。

| 使用率 | 状態 | アクション |
|--------|------|-----------|
| <40% | 最適 | そのまま継続 |
| 40-60% | 許容 | 監視継続 |
| 60-80% | 警告 | **即座にコンパクション実行** |
| >80% | 危険 | **リセット**、サマリーから再開 |

### Research-Plan-Implement ワークフロー

すべての複雑なタスクを3フェーズに分解：

```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│   Research   │ → │    Plan     │ → │  Implement   │
│   (調査)     │    │   (計画)    │    │   (実装)    │
└─────────────┘    └─────────────┘    └─────────────┘
      ↓                  ↓                  ↓
 research.md         plan.md          output/result
 (500字以内)         (800字以内)
```

### RecursiveThink用：エージェント数制限

**問題タイプ別最大エージェント数**:

| 問題タイプ | 最大エージェント数 | 理由 |
|------------|-------------------|------|
| 技術的問題 | 3名 | 焦点を絞った分析 |
| 社会的問題 | 3名 | 多角的だが集中的 |
| 歴史的問題 | 3名 | 文脈重視 |
| 学際的問題 | 4名（従来6名→削減） | 必要最小限の多様性 |

**各エージェントの出力上限**:
- 体系的分析者: 400字
- 創造的探索者: 300字
- 批判的評価者: 350字
- 統合的総合者: 500字
- 実践的戦略家: 400字
- 引用検証専門家: 300字

### Theory Building用：対話ラウンド制限

**推奨**: 25-30ラウンド以内で理論収束

| 対話段階 | コンテキスト予算 | 主要活動 |
|----------|----------------|----------|
| 初期探索（1-5ラウンド） | ≤30% | 現象の明確化 |
| 仮説生成（6-15ラウンド） | ≤50% | 競合仮説生成 |
| 深堀り（16-25ラウンド） | ≤60% | Feynman/Einstein適用 |
| 収束（26-30ラウンド） | ≤40% | 理論確定 |

**超過時のアクション**:
1. 現時点のサマリーを生成
2. 対話を一度終了
3. サマリーを入力として新しい対話を開始

### 意図的コンパクション

**各フェーズ完了時の圧縮テンプレート**:

```markdown
## [フェーズ名]サマリー（[字数上限]字以内）

### 完了事項
- [箇条書き3-5項目]

### 主要発見/決定
- [重要ポイント2-3個]

### 次フェーズへの引継ぎ
- [必要情報のみ、1-2項目]
```

**破棄するもの**:
- 詳細な探索過程
- 却下した選択肢の詳細
- 冗長な説明

### 12 Factor Agents 主要原則

| Factor | 原則 | 適用方法 |
|--------|------|----------|
| Factor 3 | Own Your Context Window | 使用率40-60%を維持 |
| Factor 6 | Launch/Pause/Resume | フェーズ間の状態保存 |
| Factor 8 | Own Your Control Flow | Research-Plan-Implement |
| Factor 9 | Compact Errors | エラーを100字以内に圧縮 |
| Factor 10 | Small, Focused Agents | 3-4エージェントに制限 |

### 品質チェックリスト（HumanLayer統合）

実行完了時に確認:

- [ ] コンテキスト使用率 <60%
- [ ] Research-Plan-Implementフローに準拠
- [ ] 各フェーズのサマリーが字数制限内
- [ ] エージェント数 ≤4名（RecursiveThink）
- [ ] 対話ラウンド ≤30回（Theory Building）
- [ ] エラーが100字以内に圧縮

### 参照

詳細なContext Engineering原則については `context-engineering` スキルを参照:
- 12 Factor Agents完全版
- ACE-FCA（Advanced Context Engineering for Coding Agents）
- サブエージェントパターン

---

**バージョン**: 2.1.0
**更新日**: 2025-12-06
**統合元**: recursive-think, theory-building, context-engineering (v2.0), brainstorming
**主要更新**: HumanLayer 12 Factor Agents / ACE-FCA統合（コンテキスト予算管理、意図的コンパクション、Research-Plan-Implementワークフロー）
