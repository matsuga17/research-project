---
name: content-extractor
description: |
  URLã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è‡ªå‹•æŠ½å‡ºã™ã‚‹çµ±åˆã‚¹ã‚­ãƒ«ï¼ˆæ—§Tapestryï¼‰ã€‚ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’åŒ…æ‹¬ï¼š
  (1) YouTubeå‹•ç”»ã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆå–å¾—
  (2) Webè¨˜äº‹ãƒ»ãƒ–ãƒ­ã‚°ã®æœ¬æ–‡æŠ½å‡º
  (3) PDFãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
  (4) ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ä½œæˆï¼ˆShip-Learn-Nextå½¢å¼ï¼‰
  ãƒˆãƒªã‚¬ãƒ¼ï¼šã€Œtapestryã€ã€Œweaveã€ã€ŒYouTube ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€ã€Œè¨˜äº‹æŠ½å‡ºã€ã€ŒPDFæŠ½å‡ºã€ã€Œã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—ã€
allowed-tools: Bash,Read,Write
---

# Content Extractor - ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºçµ±åˆã‚¹ã‚­ãƒ«

## æ¦‚è¦

URLã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è‡ªå‹•æ¤œå‡ºãƒ»æŠ½å‡ºã™ã‚‹çµ±åˆã‚¹ã‚­ãƒ«ã§ã™ã€‚YouTubeå‹•ç”»ã€Webè¨˜äº‹ã€PDFãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãªã©ã€æ§˜ã€…ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—ã«å¯¾å¿œã—ã€ã‚¯ãƒªãƒ¼ãƒ³ãªãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚

**çµ±åˆå…ƒã‚¹ã‚­ãƒ«**ï¼š
- tapestryï¼ˆçµ±åˆã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼‰
- youtube-transcriptï¼ˆYouTubeå­—å¹•å–å¾—ï¼‰
- article-extractorï¼ˆè¨˜äº‹æŠ½å‡ºï¼‰

## When to Use This Skill

ä»¥ä¸‹ã®å ´åˆã«ã“ã®ã‚¹ã‚­ãƒ«ã‚’ä½¿ç”¨ï¼š

- YouTubeå‹•ç”»ã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆå–å¾—
- Webè¨˜äº‹ãƒ»ãƒ–ãƒ­ã‚°è¨˜äº‹ã®æœ¬æ–‡æŠ½å‡º
- PDFãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›
- URLã‹ã‚‰ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è‡ªå‹•æŠ½å‡º

**ãƒˆãƒªã‚¬ãƒ¼ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**ï¼š
- ã€Œtapestry [URL]ã€ã€Œweave [URL]ã€
- ã€ŒYouTube ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€ã€Œå­—å¹•å–å¾—ã€
- ã€Œè¨˜äº‹æŠ½å‡ºã€ã€Œè¨˜äº‹ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€
- ã€ŒPDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã€
- ã€Œã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—ã€ã€Œextract [URL]ã€

---

# Part 1: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—è‡ªå‹•æ¤œå‡º

## 1.1 URLåˆ†æãƒ­ã‚¸ãƒƒã‚¯

```bash
URL="$1"

# YouTubeæ¤œå‡º
if [[ "$URL" =~ youtube\.com/watch || "$URL" =~ youtu\.be/ || "$URL" =~ youtube\.com/shorts ]]; then
    CONTENT_TYPE="youtube"

# PDFæ¤œå‡º
elif [[ "$URL" =~ \.pdf$ ]]; then
    CONTENT_TYPE="pdf"

# PDFãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ˜ãƒƒãƒ€ãƒ¼ãƒã‚§ãƒƒã‚¯
elif curl -sI "$URL" | grep -iq "Content-Type: application/pdf"; then
    CONTENT_TYPE="pdf"

# ãã®ä»–ã¯Article
else
    CONTENT_TYPE="article"
fi

echo "Detected: $CONTENT_TYPE"
```

## 1.2 ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—

| ã‚¿ã‚¤ãƒ— | ãƒ‘ã‚¿ãƒ¼ãƒ³ | ä½¿ç”¨ãƒ„ãƒ¼ãƒ« |
|--------|----------|------------|
| YouTube | youtube.com/watch, youtu.be/ | yt-dlp |
| Article | http(s)://* (éYouTube, éPDF) | reader, trafilatura |
| PDF | *.pdf, Content-Type: application/pdf | pdftotext |

---

# Part 2: YouTube ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

## 2.1 åŸºæœ¬ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

```bash
# 1. yt-dlpã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª
if ! command -v yt-dlp &> /dev/null; then
    echo "Installing yt-dlp..."
    brew install yt-dlp  # macOS
    # ã¾ãŸã¯: pip3 install yt-dlp
fi

# 2. åˆ©ç”¨å¯èƒ½ãªå­—å¹•ã‚’ç¢ºèª
yt-dlp --list-subs "$VIDEO_URL"

# 3. æ‰‹å‹•å­—å¹•ã‚’è©¦è¡Œï¼ˆé«˜å“è³ªï¼‰
if yt-dlp --write-sub --skip-download --output "transcript" "$VIDEO_URL" 2>/dev/null; then
    echo "Manual subtitles downloaded"
else
    # 4. è‡ªå‹•ç”Ÿæˆå­—å¹•ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    yt-dlp --write-auto-sub --skip-download --output "transcript" "$VIDEO_URL"
fi

# 5. ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ï¼ˆé‡è¤‡é™¤å»ï¼‰
python3 -c "
import sys, re
seen = set()
with open('transcript.en.vtt', 'r') as f:
    for line in f:
        line = line.strip()
        if line and not line.startswith('WEBVTT') and not line.startswith('Kind:') and not line.startswith('Language:') and '-->' not in line:
            clean = re.sub('<[^>]*>', '', line)
            clean = clean.replace('&amp;', '&').replace('&gt;', '>').replace('&lt;', '<')
            if clean and clean not in seen:
                print(clean)
                seen.add(clean)
" > "${VIDEO_TITLE}.txt"

# 6. ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
rm -f transcript.en.vtt
```

## 2.2 å®Œå…¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# YouTube Transcript Downloader

VIDEO_URL="$1"

if [ -z "$VIDEO_URL" ]; then
    echo "Usage: youtube-transcript <URL>"
    exit 1
fi

# yt-dlpç¢ºèª
if ! command -v yt-dlp &> /dev/null; then
    echo "Installing yt-dlp..."
    if command -v brew &> /dev/null; then
        brew install yt-dlp
    else
        pip3 install yt-dlp
    fi
fi

# å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«å–å¾—
VIDEO_TITLE=$(yt-dlp --print "%(title)s" "$VIDEO_URL" | tr '/' '_' | tr ':' '-' | tr '?' '' | tr '"' '')

echo "Downloading transcript for: $VIDEO_TITLE"

# å­—å¹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
OUTPUT_NAME="temp_transcript"
if ! yt-dlp --write-sub --skip-download --output "$OUTPUT_NAME" "$VIDEO_URL" 2>/dev/null; then
    if ! yt-dlp --write-auto-sub --skip-download --output "$OUTPUT_NAME" "$VIDEO_URL" 2>/dev/null; then
        echo "Error: No subtitles available"
        exit 1
    fi
fi

# VTTãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
VTT_FILE=$(ls ${OUTPUT_NAME}*.vtt 2>/dev/null | head -n 1)
if [ -z "$VTT_FILE" ]; then
    echo "Error: No VTT file found"
    exit 1
fi

# ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ï¼ˆé‡è¤‡é™¤å»ï¼‰
python3 -c "
import sys, re
seen = set()
with open('$VTT_FILE', 'r') as f:
    for line in f:
        line = line.strip()
        if line and not line.startswith('WEBVTT') and not line.startswith('Kind:') and not line.startswith('Language:') and '-->' not in line:
            clean = re.sub('<[^>]*>', '', line)
            clean = clean.replace('&amp;', '&').replace('&gt;', '>').replace('&lt;', '<')
            if clean and clean not in seen:
                print(clean)
                seen.add(clean)
" > "${VIDEO_TITLE}.txt"

# ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
rm -f "$VTT_FILE"

echo "âœ“ Saved to: ${VIDEO_TITLE}.txt"
```

## 2.3 Whisperä»£æ›¿ï¼ˆå­—å¹•ãªã—ã®å ´åˆï¼‰

```bash
# å­—å¹•ãŒåˆ©ç”¨ã§ããªã„å ´åˆã®Whisperæ–‡å­—èµ·ã“ã—
# â€»äº‹å‰ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèªãŒå¿…è¦

# éŸ³å£°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
yt-dlp -x --audio-format mp3 --output "audio_%(id)s.%(ext)s" "$VIDEO_URL"

# Whisperæ–‡å­—èµ·ã“ã—
whisper audio_*.mp3 --model base --output_format txt

# ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
rm -f audio_*.mp3
```

---

# Part 3: Webè¨˜äº‹æŠ½å‡º

## 3.1 æŠ½å‡ºãƒ„ãƒ¼ãƒ«ã®å„ªå…ˆé †ä½

```
1. reader (Mozilla Readability) - æ¨å¥¨
2. trafilatura - é«˜ç²¾åº¦
3. curl + Python fallback - ä¾å­˜ãªã—
```

## 3.2 åŸºæœ¬ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

```bash
ARTICLE_URL="$1"

# ãƒ„ãƒ¼ãƒ«ç¢ºèª
if command -v reader &> /dev/null; then
    TOOL="reader"
elif command -v trafilatura &> /dev/null; then
    TOOL="trafilatura"
else
    TOOL="fallback"
fi

echo "Using: $TOOL"

case $TOOL in
    reader)
        # Mozilla Readabilityãƒ™ãƒ¼ã‚¹
        reader "$ARTICLE_URL" > temp_article.txt
        TITLE=$(head -n 1 temp_article.txt | sed 's/^# //')
        ;;

    trafilatura)
        # PythonæŠ½å‡ºã‚¨ãƒ³ã‚¸ãƒ³
        METADATA=$(trafilatura --URL "$ARTICLE_URL" --json)
        TITLE=$(echo "$METADATA" | python3 -c "import json, sys; print(json.load(sys.stdin).get('title', 'Article'))")
        trafilatura --URL "$ARTICLE_URL" --output-format txt --no-comments > temp_article.txt
        ;;

    fallback)
        # åŸºæœ¬çš„ãªHTMLè§£æ
        TITLE=$(curl -s "$ARTICLE_URL" | grep -oP '<title>\K[^<]+' | head -n 1)
        TITLE=${TITLE%% - *}
        curl -s "$ARTICLE_URL" | python3 -c "
from html.parser import HTMLParser
import sys

class ArticleExtractor(HTMLParser):
    def __init__(self):
        super().__init__()
        self.content = []
        self.skip_tags = {'script', 'style', 'nav', 'header', 'footer', 'aside', 'form'}
        self.in_content = False

    def handle_starttag(self, tag, attrs):
        if tag not in self.skip_tags and tag in {'p', 'article', 'main'}:
            self.in_content = True

    def handle_data(self, data):
        if self.in_content and data.strip():
            self.content.append(data.strip())

    def get_content(self):
        return '\n\n'.join(self.content)

parser = ArticleExtractor()
parser.feed(sys.stdin.read())
print(parser.get_content())
" > temp_article.txt
        ;;
esac

# ãƒ•ã‚¡ã‚¤ãƒ«åæ•´å½¢
FILENAME=$(echo "$TITLE" | tr '/' '-' | tr ':' '-' | tr '?' '' | tr '"' '' | cut -c 1-80 | sed 's/ *$//')
FILENAME="${FILENAME}.txt"
mv temp_article.txt "$FILENAME"

echo "âœ“ Saved to: $FILENAME"
```

## 3.3 ãƒ„ãƒ¼ãƒ«ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# reader (npm)
npm install -g @anthropic-ai/reader-cli
# ã¾ãŸã¯
npm install -g reader-cli

# trafilatura (pip)
pip3 install trafilatura
```

---

# Part 4: PDFæŠ½å‡º

## 4.1 åŸºæœ¬ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

```bash
PDF_URL="$1"

# PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
PDF_FILENAME=$(basename "$PDF_URL")
curl -L -o "$PDF_FILENAME" "$PDF_URL"

# ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
if command -v pdftotext &> /dev/null; then
    pdftotext "$PDF_FILENAME" "${PDF_FILENAME%.pdf}.txt"
    echo "âœ“ Extracted: ${PDF_FILENAME%.pdf}.txt"
else
    echo "Warning: pdftotext not found"
    echo "Install with: brew install poppler (macOS)"
    echo "            : apt install poppler-utils (Linux)"
fi
```

## 4.2 pdftotext ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# macOS
brew install poppler

# Ubuntu/Debian
apt install poppler-utils

# Windows (Chocolatey)
choco install poppler
```

---

# Part 5: çµ±åˆTapestryãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

## 5.1 å®Œå…¨çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# Tapestry: Unified Content Extraction

URL="$1"

if [ -z "$URL" ]; then
    echo "Usage: tapestry <URL>"
    exit 1
fi

echo "ğŸ§µ Tapestry Starting..."
echo "URL: $URL"
echo ""

# Step 1: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—æ¤œå‡º
if [[ "$URL" =~ youtube\.com/watch || "$URL" =~ youtu\.be/ || "$URL" =~ youtube\.com/shorts ]]; then
    CONTENT_TYPE="youtube"
elif [[ "$URL" =~ \.pdf$ ]] || curl -sI "$URL" | grep -iq "Content-Type: application/pdf"; then
    CONTENT_TYPE="pdf"
else
    CONTENT_TYPE="article"
fi

echo "ğŸ“ Detected: $CONTENT_TYPE"
echo ""

# Step 2: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡º
case $CONTENT_TYPE in
    youtube)
        echo "ğŸ“º Extracting YouTube transcript..."
        # [YouTubeæŠ½å‡ºã‚³ãƒ¼ãƒ‰]
        ;;

    article)
        echo "ğŸ“„ Extracting article..."
        # [è¨˜äº‹æŠ½å‡ºã‚³ãƒ¼ãƒ‰]
        ;;

    pdf)
        echo "ğŸ“‘ Extracting PDF..."
        # [PDFæŠ½å‡ºã‚³ãƒ¼ãƒ‰]
        ;;
esac

echo ""
echo "âœ… Tapestry Complete!"
echo "ğŸ“¥ Content saved to: $CONTENT_FILE"
```

## 5.2 å‡ºåŠ›å½¢å¼

```
âœ… Tapestry Workflow Complete!

ğŸ“¥ Content Extracted:
   âœ“ [Content type]: [Title]
   âœ“ Saved to: [filename.txt]
   âœ“ [X] words extracted

ğŸ“‹ Summary:
   [First 5 lines of content]
```

---

# Part 6: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

## 6.1 ã‚ˆãã‚ã‚‹å•é¡Œã¨å¯¾å‡¦

### yt-dlpãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„
```bash
# è‡ªå‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«è©¦è¡Œ
if ! command -v yt-dlp &> /dev/null; then
    if command -v brew &> /dev/null; then
        brew install yt-dlp
    elif command -v apt &> /dev/null; then
        sudo apt update && sudo apt install -y yt-dlp
    else
        pip3 install yt-dlp
    fi
fi
```

### å­—å¹•ãŒåˆ©ç”¨ã§ããªã„
```
1. --list-subsã§åˆ©ç”¨å¯èƒ½ãªè¨€èªã‚’ç¢ºèª
2. åˆ¥è¨€èªã®å­—å¹•ã‚’è©¦è¡Œ
3. Whisperæ–‡å­—èµ·ã“ã—ã‚’ææ¡ˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèªå¾Œï¼‰
```

### è¨˜äº‹æŠ½å‡ºãŒå¤±æ•—
```
1. ä»£æ›¿ãƒ„ãƒ¼ãƒ«ã‚’è©¦è¡Œï¼ˆreader â†’ trafilatura â†’ fallbackï¼‰
2. ãƒšã‚¤ã‚¦ã‚©ãƒ¼ãƒ«/ãƒ­ã‚°ã‚¤ãƒ³è¦ä»¶ã®å¯èƒ½æ€§ã‚’é€šçŸ¥
3. JavaScriptãŒå¤šã„ã‚µã‚¤ãƒˆã®åˆ¶é™ã‚’èª¬æ˜
```

### PDFãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºãŒç©º
```
1. OCR PDFã®å¯èƒ½æ€§ï¼ˆç”»åƒãƒ™ãƒ¼ã‚¹ï¼‰
2. ocrmypdfãªã©ã®OCRãƒ„ãƒ¼ãƒ«ã‚’ææ¡ˆ
3. æ‰‹å‹•ã§ã®ä»£æ›¿æ–¹æ³•ã‚’æ¡ˆå†…
```

---

# Part 7: èµ·å‹•ã‚³ãƒãƒ³ãƒ‰

## åŸºæœ¬ä½¿ç”¨
```
content-extractor [URL]
# ã¾ãŸã¯
tapestry [URL]
weave [URL]
```

## YouTubeå°‚ç”¨
```
youtube-transcript [YouTube URL]
```

## è¨˜äº‹å°‚ç”¨
```
article-extract [Article URL]
```

## PDFå°‚ç”¨
```
pdf-extract [PDF URL or file path]
```

---

## ä¾å­˜é–¢ä¿‚

### å¿…é ˆ
- curlï¼ˆçµ„ã¿è¾¼ã¿ï¼‰
- Python 3.x

### æ¨å¥¨
- yt-dlpï¼ˆYouTubeç”¨ï¼‰
- reader ã¾ãŸã¯ trafilaturaï¼ˆè¨˜äº‹ç”¨ï¼‰
- pdftotextï¼ˆPDFç”¨ã€popplerãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ï¼‰

### ã‚ªãƒ—ã‚·ãƒ§ãƒ³
- whisperï¼ˆå­—å¹•ãªã—ã®å ´åˆï¼‰
- ocrmypdfï¼ˆOCR PDFç”¨ï¼‰

---

## é€£æºã‚¹ã‚­ãƒ«

| ã‚¹ã‚­ãƒ«å | å½¹å‰² |
|----------|------|
| academic-research-suite | æ–‡çŒ®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ»è«–æ–‡åŸ·ç­†ãƒ»å¼•ç”¨ç®¡ç† |
| thinking-toolkit | æŠ½å‡ºã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ†æãƒ»ç†è«–æ§‹ç¯‰ |
| strategic-research-platform | ç ”ç©¶ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ»çµ±è¨ˆåˆ†æ |
| document-design-suite | å¯è¦–åŒ–ãƒ»å›³è¡¨ä½œæˆ |

---

**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0.0
**çµ±åˆæ—¥**: 2025-11-28
**çµ±åˆå…ƒ**: tapestry, youtube-transcript, article-extractor
