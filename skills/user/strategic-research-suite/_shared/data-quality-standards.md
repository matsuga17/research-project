# ãƒ‡ãƒ¼ã‚¿å“è³ªä¿è¨¼åŸºæº–

**Strategic Research Suiteå“è³ªåŸºæº–ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹**

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯Publication-readyç ”ç©¶ã®ãŸã‚ã®å“è³ªä¿è¨¼åŸºæº–ã‚’å®šç¾©ã—ã¾ã™ã€‚

## ğŸ¯ å“è³ªä¿è¨¼ã®5ã¤ã®æŸ±

### 1. Statistical Powerï¼ˆçµ±è¨ˆçš„æ¤œå‡ºåŠ›ï¼‰
### 2. Sample Qualityï¼ˆã‚µãƒ³ãƒ—ãƒ«å“è³ªï¼‰
### 3. Data Integrityï¼ˆãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ï¼‰
### 4. Measurement Validityï¼ˆæ¸¬å®šå¦¥å½“æ€§ï¼‰
### 5. Reproducibilityï¼ˆå†ç¾å¯èƒ½æ€§ï¼‰

---

## 1ï¸âƒ£ Statistical Power Analysis

### äº‹å‰æ¤œå‡ºåŠ›åˆ†æï¼ˆRequiredï¼‰

**ç›®çš„**: Type II errorï¼ˆå½é™°æ€§ï¼‰ã‚’é¿ã‘ã‚‹

**åŸºæº–**:
- Target power: **â‰¥ 0.80** (80%)
- Î± level: 0.05
- Effect size: å…ˆè¡Œç ”ç©¶ã®ãƒ¡ã‚¿åˆ†æã‹ã‚‰æ¨å®š

**è¨ˆç®—å¼ï¼ˆTwo-sample t-testï¼‰**:
```
n = 2 Ã— (Z_Î±/2 + Z_Î²)Â² Ã— ÏƒÂ² / Î´Â²

Where:
- Z_Î±/2 = 1.96 (Î± = 0.05)
- Z_Î² = 0.84 (power = 0.80)
- Ïƒ = æ¨™æº–åå·®
- Î´ = åŠ¹æœé‡
```

**Pythonå®Ÿè£…**:
```python
from statsmodels.stats.power import TTestIndPower

analysis = TTestIndPower()
sample_size = analysis.solve_power(
    effect_size=0.35,  # Cohen's d
    alpha=0.05,
    power=0.80,
    alternative='two-sided'
)
```

**å ±å‘Šä¾‹**:
```
ã€Œå…ˆè¡Œç ”ç©¶ï¼ˆSmith et al., 2020ï¼‰ã«åŸºã¥ãã€æœŸå¾…åŠ¹æœé‡ã‚’d=0.35ã¨
æ¨å®šã—ãŸã€‚80%æ¤œå‡ºåŠ›ï¼ˆÎ±=0.05ï¼‰ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã€1ã‚°ãƒ«ãƒ¼ãƒ—ã‚ãŸã‚Š
130ç¤¾ãŒå¿…è¦ã¨ç®—å‡ºã•ã‚ŒãŸã€‚æœ¬ç ”ç©¶ã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆN=312ç¤¾ï¼‰ã¯ååˆ†ãª
çµ±è¨ˆçš„æ¤œå‡ºåŠ›ï¼ˆå®Ÿç¾æ¤œå‡ºåŠ›=87%ï¼‰ã‚’æœ‰ã—ã¦ã„ã‚‹ã€‚ã€
```

### äº‹å¾Œæ¤œå‡ºåŠ›åˆ†æï¼ˆPost-hocï¼‰

**å®Ÿæ–½ã‚¿ã‚¤ãƒŸãƒ³ã‚°**: åˆ†æå®Œäº†å¾Œ

**ç›®çš„**: 
- éæœ‰æ„çµæœã®è§£é‡ˆï¼ˆæ¤œå‡ºåŠ›ä¸è¶³ vs. çœŸã®åŠ¹æœãªã—ï¼‰
- æœ‰æ„çµæœã®ä¿¡é ¼æ€§ç¢ºèª

**Warning**: 
- äº‹å¾Œæ¤œå‡ºåŠ›ã®ã¿ã§ã®åˆ¤æ–­ã¯ä¸é©åˆ‡
- å¿…ãšäº‹å‰æ¤œå‡ºåŠ›åˆ†æã‚’å®Ÿæ–½

---

## 2ï¸âƒ£ Sample Quality Standards

### ã‚µãƒã‚¤ãƒãƒ«ãƒã‚¤ã‚¢ã‚¹å¯¾ç­–ï¼ˆCriticalï¼‰

**å•é¡Œ**: ç¾å­˜ä¼æ¥­ã®ã¿åˆ†æ â†’ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹éå¤§è©•ä¾¡

**å¯¾ç­–**:
1. **Delisted firmsã‚’å«ã‚ã‚‹**
   - CRSPã®delistingæƒ…å ±çµ±åˆ
   - ãƒ‡ãƒªã‚¹ãƒˆç†ç”±ã®åˆ†é¡ï¼ˆmerger, liquidation, etc.ï¼‰

2. **Attritionåˆ†æ**
   - ãƒ‡ãƒªã‚¹ãƒˆä¼æ¥­ vs. å­˜ç¶šä¼æ¥­ã®ç‰¹æ€§æ¯”è¼ƒ
   - t-test for systematic differences

**åŸºæº–**:
- Attrition rate < 30%: è¨±å®¹ç¯„å›²
- Attrition rate 30-50%: Selection modelå¿…è¦ï¼ˆHeckmanï¼‰
- Attrition rate > 50%: æ·±åˆ»ãªãƒã‚¤ã‚¢ã‚¹

**Pythonå®Ÿè£…**:
```python
# Attritionåˆ†æ
df_panel['attrite'] = df_panel.groupby('firm_id')['year'].transform(
    lambda x: 1 if x.max() < df_panel['year'].max() else 0
)

from scipy.stats import ttest_ind

attrite_firms = df_panel[df_panel['attrite'] == 1]
survive_firms = df_panel[df_panel['attrite'] == 0]

for var in ['roa', 'total_assets', 'leverage']:
    t, p = ttest_ind(
        attrite_firms[var].dropna(),
        survive_firms[var].dropna()
    )
    if p < 0.05:
        print(f"WARNING: {var} significantly different (p={p:.4f})")
```

### Winsorizationï¼ˆå¤–ã‚Œå€¤å‡¦ç†ï¼‰

**åŸºæº–**: 1%ile & 99%ile

**å¯¾è±¡å¤‰æ•°**: ã™ã¹ã¦ã®é€£ç¶šå¤‰æ•°

**ç†ç”±**: 
- æ¥µç«¯å€¤ã®å½±éŸ¿ç·©å’Œ
- ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯æ¤œå®šã®å‰ææ”¹å–„

**Pythonå®Ÿè£…**:
```python
from scipy.stats.mstats import winsorize

continuous_vars = ['roa', 'leverage', 'tobins_q', 'rd_intensity']

for var in continuous_vars:
    df[f'{var}_winsor'] = winsorize(
        df[var],
        limits=[0.01, 0.01],
        nan_policy='omit'
    )
```

**å ±å‘Š**:
```
ã€Œã™ã¹ã¦ã®é€£ç¶šå¤‰æ•°ã‚’1ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åŠã³99ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ã§
winsorizeã—ãŸã€‚ã€
```

---

## 3ï¸âƒ£ Data Integrity Checks

### Benford's Law Test

**ç›®çš„**: ãƒ‡ãƒ¼ã‚¿ä¸æ­£ãƒ»ã‚¨ãƒ©ãƒ¼ã®æ¤œå‡º

**å¯¾è±¡**: è‡ªç„¶ç™ºç”Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆè²¡å‹™ãƒ‡ãƒ¼ã‚¿ï¼‰

**åŸºæº–**:
- Ï‡Â² test: p > 0.05 â†’ åˆæ ¼
- p < 0.05 â†’ è¦èª¿æŸ»

**Pythonå®Ÿè£…**:
```python
def benford_test(data):
    """Benford's Lawæ¤œå®š"""
    import numpy as np
    from scipy.stats import chisquare
    
    # å…ˆé ­æ¡æŠ½å‡º
    first_digits = [int(str(abs(x))[0]) for x in data if x != 0]
    
    # è¦³æ¸¬åº¦æ•°
    observed = np.bincount(first_digits)[1:10]
    
    # Benford's Lawã®æœŸå¾…åº¦æ•°
    expected = [np.log10(1 + 1/d) * len(first_digits) for d in range(1, 10)]
    
    # Ï‡Â² test
    chi2, p_value = chisquare(observed, expected)
    
    return {
        'chi2': chi2,
        'p_value': p_value,
        'conforms': p_value > 0.05
    }
```

**ä¾‹å¤–**ï¼ˆBenford's LawãŒé©ç”¨ã•ã‚Œãªã„ï¼‰:
- IDç•ªå·
- äººç‚ºçš„åˆ¶ç´„ï¼ˆæœ€ä½è³‡æœ¬é‡‘è¦ä»¶ç­‰ï¼‰
- å°ã‚µãƒ³ãƒ—ãƒ«ï¼ˆN < 100ï¼‰

### ä¼šè¨ˆæ’ç­‰å¼æ¤œè¨¼

**æ’ç­‰å¼**:
```
ç·è³‡ç”£ = ç·è² å‚µ + æ ªä¸»è³‡æœ¬
```

**è¨±å®¹èª¤å·®**: < 1%

**Pythonå®Ÿè£…**:
```python
df['bs_error'] = abs(df['at'] - (df['lt'] + df['ceq']))
df['bs_error_pct'] = df['bs_error'] / df['at']

violations = df[df['bs_error_pct'] > 0.01]

if len(violations) / len(df) > 0.05:
    print("WARNING: >5% balance sheet errors")
```

### æ§‹é€ å¤‰åŒ–æ¤œå®šï¼ˆChow Testï¼‰

**ç›®çš„**: ãƒ‡ãƒ¼ã‚¿ã®æ™‚ç³»åˆ—å®‰å®šæ€§ç¢ºèª

**æ–¹æ³•**: 
1. æ™‚ç³»åˆ—ã‚’sub-periodã«åˆ†å‰²
2. å„æœŸé–“ã§å›å¸°
3. ä¿‚æ•°ã®å®‰å®šæ€§æ¤œå®š

**åŸºæº–**:
- F-test: p > 0.05 â†’ å®‰å®š
- p < 0.05 â†’ æ§‹é€ å¤‰åŒ–ã‚ã‚Š

**å¯¾å‡¦**:
- æ—¢çŸ¥ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆ2008é‡‘èå±æ©Ÿç­‰ï¼‰â†’ Period dummyã§çµ±åˆ¶
- æœªçŸ¥ã‚¤ãƒ™ãƒ³ãƒˆ â†’ åŸå› èª¿æŸ»ã€æœŸé–“åˆ†å‰²åˆ†æ

---

## 4ï¸âƒ£ Measurement Validity

### Construct Validityï¼ˆæ§‹æˆæ¦‚å¿µå¦¥å½“æ€§ï¼‰

**åŸºæº–**:
1. **Face validity**: æ¸¬å®šãŒç›´æ„Ÿçš„ã«å¦¥å½“
2. **Content validity**: æ¦‚å¿µã®å…¨å´é¢ã‚’ã‚«ãƒãƒ¼
3. **Criterion validity**: ä»–ã®åŸºæº–ã¨ç›¸é–¢

**Example: Dynamic Capability**

âŒ **Poor measurement**:
```
Dynamic Capability = R&Dæ”¯å‡ºã®ã¿
```

âœ… **Good measurement**:
```
Dynamic Capability = 
  - R&D intensity
  - è£½å“é–‹ç™ºã‚µã‚¤ã‚¯ãƒ«æ™‚é–“
  - å¸‚å ´é©å¿œé€Ÿåº¦
  - çµ„ç¹”æŸ”è»Ÿæ€§æŒ‡æ¨™
ã®çµ±åˆæŒ‡æ¨™
```

### Reliabilityï¼ˆä¿¡é ¼æ€§ï¼‰

**Internal Consistency**:
- Cronbach's Î± â‰¥ 0.70 (è¨±å®¹)
- Cronbach's Î± â‰¥ 0.80 (è‰¯å¥½)

**é©ç”¨å ´é¢**: 
- è¤‡æ•°é …ç›®ã‚’çµ±åˆã™ã‚‹å ´åˆ
- ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆèª¿æŸ»ãƒ‡ãƒ¼ã‚¿

**Pythonå®Ÿè£…**:
```python
def cronbach_alpha(items):
    """Cronbach's Î±è¨ˆç®—"""
    item_vars = items.var(axis=0, ddof=1)
    total_var = items.sum(axis=1).var(ddof=1)
    n_items = items.shape[1]
    
    alpha = (n_items / (n_items - 1)) * (1 - item_vars.sum() / total_var)
    return alpha
```

### Convergent & Discriminant Validity

**Convergent**: åŒä¸€æ¦‚å¿µã®ç•°ãªã‚‹æ¸¬å®šãŒé«˜ç›¸é–¢

**Discriminant**: ç•°ãªã‚‹æ¦‚å¿µã®æ¸¬å®šãŒä½ç›¸é–¢

**åŸºæº–**:
- Convergent: r > 0.50
- Discriminant: r < 0.30

---

## 5ï¸âƒ£ Reproducibility Standards

### AEA (American Economic Association) åŸºæº–

**Required Elements**:

1. **Data Availability Statement**
   ```
   ã€Œãƒ‡ãƒ¼ã‚¿ã¯[ã‚½ãƒ¼ã‚¹å]ã‹ã‚‰[ã‚¢ã‚¯ã‚»ã‚¹æ–¹æ³•]ã§å…¥æ‰‹å¯èƒ½ã€‚
   æœ¬ç ”ç©¶ã§ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯[URL]ã§å…¬é–‹ã—ã¦ã„ã‚‹ã€‚ã€
   ```

2. **Code Availability**
   ```
   ã€Œã™ã¹ã¦ã®åˆ†æã‚³ãƒ¼ãƒ‰ã¯[GitHub URL]ã§å…¬é–‹ã—ã¦ã„ã‚‹ã€‚ã€
   ```

3. **Computational Requirements**
   ```
   - Python 3.9+
   - RAM: 16GB minimum
   - Runtime: ç´„2æ™‚é–“
   ```

4. **Random Seed Documentation**
   ```python
   np.random.seed(42)
   random.seed(42)
   ```

### Replication Package Checklist

- [ ] README.md with execution instructions
- [ ] Data sources documented
- [ ] All scripts numbered sequentially
- [ ] Requirements.txt / environment.yml
- [ ] Expected output described
- [ ] Known limitations documented
- [ ] Contact information provided

### Docker Environmentï¼ˆæ¨å¥¨ï¼‰

**åˆ©ç‚¹**:
- ç’°å¢ƒã®å®Œå…¨å†ç¾
- OSä¾å­˜æ€§ã®æ’é™¤
- ãƒãƒ¼ã‚¸ãƒ§ãƒ³å›ºå®š

**Dockerfile example**:
```dockerfile
FROM python:3.9-slim

WORKDIR /research

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

CMD ["python", "run_all.py"]
```

---

## ğŸ“Š Quality Score Matrix

å„åŸºæº–ã«å¯¾ã—ã¦ã‚¹ã‚³ã‚¢ã‚’ä»˜ä¸ï¼š

| åŸºæº– | Weight | Score (0-10) | Weighted |
|------|--------|--------------|----------|
| Statistical Power | 20% | 8 | 1.6 |
| Sample Quality | 20% | 7 | 1.4 |
| Data Integrity | 20% | 9 | 1.8 |
| Measurement Validity | 20% | 8 | 1.6 |
| Reproducibility | 20% | 10 | 2.0 |
| **Total** | 100% | - | **8.4** |

**è§£é‡ˆ**:
- Score â‰¥ 8.0: Publication-ready (Top journals)
- Score 6.0-7.9: Revision needed
- Score < 6.0: Major revision required

---

## ğŸš¨ Critical Failures (å³åº§ã«å¯¾å‡¦)

ä»¥ä¸‹ã®ã„ãšã‚Œã‹ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã€åˆ†æã‚’ä¸­æ–­ã—ã¦å¯¾å‡¦ï¼š

1. **Power < 0.50**: ã‚µãƒ³ãƒ—ãƒ«ä¸è¶³
2. **Benford p < 0.001**: ãƒ‡ãƒ¼ã‚¿ä¸æ­£ã®å¯èƒ½æ€§
3. **BS error > 10%**: æ·±åˆ»ãªãƒ‡ãƒ¼ã‚¿å“è³ªå•é¡Œ
4. **VIF > 20**: æ¥µç«¯ãªå¤šé‡å…±ç·šæ€§
5. **Attrition > 50%**: Selection biasãŒæ·±åˆ»

---

## ğŸ“ˆ Reporting Template

### Methods Section

```markdown
## 3.3 Data Quality Assurance

We conducted comprehensive quality assurance following best practices 
(Smith & Jones, 2020).

**Statistical Power**: A priori power analysis indicated that our sample 
(N=312 firms) provides 87% power to detect a medium effect (d=0.35) 
at Î±=0.05.

**Survivor Bias**: We included delisted firms using CRSP delisting data, 
resulting in an attrition rate of 18%. t-tests revealed no significant 
differences in key variables between surviving and delisted firms.

**Outlier Treatment**: All continuous variables were winsorized at the 
1st and 99th percentiles to mitigate extreme value influence.

**Data Integrity**: Benford's Law tests (Ï‡Â²=12.3, p=0.14) and balance 
sheet identity checks (error rate <1%) confirmed data integrity.

**Structural Stability**: Chow tests revealed no significant structural 
breaks across the study period (F=1.8, p=0.12).
```

---

## ğŸ”— é–¢é€£ã‚¹ã‚­ãƒ«

ã“ã®å“è³ªåŸºæº–ã¯ä»¥ä¸‹ã®ã‚¹ã‚­ãƒ«ã§å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™ï¼š

- **1-core-workflow**: Phase 6ã§å“è³ªä¿è¨¼ã‚’å®Ÿè¡Œ
- **3-statistical-methods**: çµ±è¨ˆçš„æ¤œå‡ºåŠ›åˆ†æã®è©³ç´°
- **8-automation**: è‡ªå‹•å“è³ªãƒã‚§ãƒƒã‚¯ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

---

**ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯å…¨ã‚¹ã‚­ãƒ«ã‹ã‚‰å‚ç…§ã•ã‚Œã¾ã™**

Publication-readyç ”ç©¶ã®ãŸã‚ã«ã€ã“ã‚Œã‚‰ã®åŸºæº–ã‚’å¿…ãšæº€ãŸã—ã¦ãã ã•ã„ã€‚

æœ€çµ‚æ›´æ–°: 2025-11-01
Version: 4.0
