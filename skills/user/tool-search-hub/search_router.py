#!/usr/bin/env python3
"""
Search Router - çµ±åˆã‚¯ã‚¨ãƒªãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ»æ¤œç´¢æœ€é©åŒ–

Usage:
    python search_router.py --query "PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º"
    python search_router.py --query "æœ€æ–°ã®AIè«–æ–‡" --mode research
    python search_router.py --analyze "ä¼æ¥­è²¡å‹™ãƒ‡ãƒ¼ã‚¿åé›†æ–¹æ³•"
"""

import argparse
import json
import re
from dataclasses import dataclass, asdict
from typing import Optional
from enum import Enum

# ============================================================
# Query Classification
# ============================================================

class QueryType(Enum):
    MCP_TOOL = "mcp_tool"           # MCPãƒ„ãƒ¼ãƒ«æ¤œç´¢
    SKILL = "skill"                  # ã‚¹ã‚­ãƒ«æ¨è–¦
    LIBRARY = "library"              # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæ¤œç´¢
    WEB_SEARCH = "web_search"        # Webæ¤œç´¢
    ACADEMIC = "academic"            # å­¦è¡“æ¤œç´¢
    CODE = "code"                    # ã‚³ãƒ¼ãƒ‰æ¤œç´¢
    DATA = "data"                    # ãƒ‡ãƒ¼ã‚¿åé›†
    COMPOSITE = "composite"          # è¤‡åˆã‚¯ã‚¨ãƒª

@dataclass
class QueryAnalysis:
    original: str
    type: QueryType
    keywords: list[str]
    suggested_tools: list[str]
    suggested_skills: list[str]
    search_strategy: str
    confidence: float

# ============================================================
# Keyword Patterns
# ============================================================

PATTERNS = {
    QueryType.MCP_TOOL: [
        r"ãƒ„ãƒ¼ãƒ«.*æ¤œç´¢", r"tool.*search", r"mcp.*ä¸€è¦§",
        r"ã©ã®.*ãƒ„ãƒ¼ãƒ«", r"åˆ©ç”¨å¯èƒ½ãª.*ãƒ„ãƒ¼ãƒ«",
    ],
    QueryType.SKILL: [
        r"ã‚¹ã‚­ãƒ«", r"skill", r"ã©ã†ã™ã‚Œã°", r"æ–¹æ³•",
        r"ã‚„ã‚Šæ–¹", r"æ‰‹é †", r"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼",
    ],
    QueryType.LIBRARY: [
        r"ãƒ©ã‚¤ãƒ–ãƒ©ãƒª", r"ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸", r"library", r"package",
        r"npm", r"pip", r"ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«", r"æ¯”è¼ƒ",
    ],
    QueryType.ACADEMIC: [
        r"è«–æ–‡", r"ç ”ç©¶", r"paper", r"research", r"å¼•ç”¨",
        r"æ–‡çŒ®", r"å­¦è¡“", r"journal", r"scholar",
    ],
    QueryType.CODE: [
        r"ã‚³ãƒ¼ãƒ‰", r"å®Ÿè£…", r"code", r"ã‚¹ã‚¯ãƒªãƒ—ãƒˆ",
        r"python", r"javascript", r"typescript",
    ],
    QueryType.DATA: [
        r"ãƒ‡ãƒ¼ã‚¿.*åé›†", r"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ", r"api.*å–å¾—",
        r"ä¼æ¥­.*ãƒ‡ãƒ¼ã‚¿", r"è²¡å‹™.*ãƒ‡ãƒ¼ã‚¿", r"scraping",
    ],
}

# ============================================================
# Tool/Skill Mappings
# ============================================================

KEYWORD_TO_TOOLS = {
    "pdf": ["view", "desktop-commander:read_file", "omnisearch:jina_reader_process"],
    "excel": ["desktop-commander:start_process", "Filesystem:read_file"],
    "web": ["omnisearch:tavily_search", "omnisearch:brave_search", "web_search"],
    "browser": ["playwright:browser_navigate", "playwright:browser_click"],
    "file": ["Filesystem:read_file", "desktop-commander:read_file", "view"],
    "search": ["omnisearch:tavily_search", "think-tank:exa_search", "web_search"],
    "youtube": ["youtube-transcript:youtube_get_transcript"],
    "è«–æ–‡": ["google-scholar:search_google_scholar_key_words", "semantic-scholar:search_semantic_scholar"],
    "research": ["google-scholar:search_google_scholar_key_words", "semantic-scholar:search_semantic_scholar"],
    "memory": ["think-tank:upsert_entities", "memory:create_entities"],
    "task": ["taskmaster-ai:add_task", "think-tank:plan_tasks"],
    "think": ["think-tank:think", "sequential-thinking:sequentialthinking"],
    "ãƒ‡ãƒ¼ã‚¿": ["Coupler.io:get-data", "desktop-commander:start_process"],
}

KEYWORD_TO_SKILLS = {
    "è«–æ–‡": ["academic-research-suite"],
    "æ–‡çŒ®": ["academic-research-suite"],
    "research": ["academic-research-suite", "strategic-research-platform"],
    "ãƒ‡ãƒ¼ã‚¿åé›†": ["research-data-hub"],
    "ä¼æ¥­": ["research-data-hub"],
    "è²¡å‹™": ["research-data-hub", "strategic-research-platform"],
    "ã‚¹ãƒ©ã‚¤ãƒ‰": ["document-design-suite"],
    "ãƒ—ãƒ¬ã‚¼ãƒ³": ["document-design-suite"],
    "è¡¨": ["document-design-suite"],
    "ã‚°ãƒ©ãƒ•": ["document-design-suite"],
    "æˆ¦ç•¥": ["strategic-research-platform"],
    "åˆ†æ": ["strategic-research-platform", "thinking-toolkit"],
    "è€ƒãˆ": ["thinking-toolkit"],
    "youtube": ["content-extractor"],
    "url": ["content-extractor"],
    "pdf": ["document-design-suite"],
    "ãƒã‚¤ã‚ª": ["scientific-databases"],
    "ã‚²ãƒãƒ ": ["scientific-databases"],
}

# ============================================================
# Search API Recommendations
# ============================================================

SEARCH_STRATEGIES = {
    "academic": {
        "primary": ["google-scholar:search_google_scholar_key_words"],
        "secondary": ["semantic-scholar:search_semantic_scholar"],
        "fallback": ["think-tank:exa_search"],
        "description": "å­¦è¡“è«–æ–‡æ¤œç´¢: Google Scholar â†’ Semantic Scholar â†’ Exa"
    },
    "technical": {
        "primary": ["omnisearch:brave_search"],
        "secondary": ["omnisearch:tavily_search"],
        "fallback": ["web_search"],
        "description": "æŠ€è¡“ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢: Brave (site:æ¼”ç®—å­) â†’ Tavily â†’ æ±ç”¨æ¤œç´¢"
    },
    "news": {
        "primary": ["omnisearch:tavily_search"],
        "secondary": ["web_search"],
        "fallback": ["think-tank:exa_search"],
        "description": "æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹: Tavily (é«˜ç²¾åº¦) â†’ Webæ¤œç´¢ â†’ Exa"
    },
    "code": {
        "primary": ["omnisearch:brave_search"],
        "secondary": ["Context7:get-library-docs"],
        "fallback": ["web_search"],
        "description": "ã‚³ãƒ¼ãƒ‰æ¤œç´¢: Brave (site:github.com) â†’ Context7 â†’ æ±ç”¨æ¤œç´¢"
    },
    "company": {
        "primary": ["omnisearch:tavily_search"],
        "secondary": ["web_search"],
        "fallback": ["research-data-hub (SEC EDGAR)"],
        "description": "ä¼æ¥­æƒ…å ±: Tavily â†’ Webæ¤œç´¢ â†’ SEC EDGAR API"
    },
    "general": {
        "primary": ["web_search"],
        "secondary": ["omnisearch:tavily_search"],
        "fallback": ["omnisearch:brave_search"],
        "description": "ä¸€èˆ¬æ¤œç´¢: æ±ç”¨æ¤œç´¢ â†’ Tavily â†’ Brave"
    }
}

# ============================================================
# Query Analyzer
# ============================================================

def classify_query(query: str) -> QueryType:
    """ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ—ã‚’åˆ†é¡"""
    query_lower = query.lower()
    
    scores = {qt: 0 for qt in QueryType}
    
    for query_type, patterns in PATTERNS.items():
        for pattern in patterns:
            if re.search(pattern, query_lower, re.IGNORECASE):
                scores[query_type] += 1
    
    # è¤‡æ•°ã‚¿ã‚¤ãƒ—ãŒé«˜ã‚¹ã‚³ã‚¢ãªã‚‰è¤‡åˆ
    high_scores = [qt for qt, score in scores.items() if score > 0]
    if len(high_scores) > 1:
        return QueryType.COMPOSITE
    elif high_scores:
        return high_scores[0]
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåˆ¤å®š
    if any(kw in query_lower for kw in ["è«–æ–‡", "ç ”ç©¶", "paper"]):
        return QueryType.ACADEMIC
    elif any(kw in query_lower for kw in ["ãƒ©ã‚¤ãƒ–ãƒ©ãƒª", "ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸", "pip", "npm"]):
        return QueryType.LIBRARY
    elif any(kw in query_lower for kw in ["ãƒ„ãƒ¼ãƒ«", "tool", "mcp"]):
        return QueryType.MCP_TOOL
    
    return QueryType.WEB_SEARCH

def extract_keywords(query: str) -> list[str]:
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º"""
    # æ—¥æœ¬èªã¨è‹±èªã®ä¸¡æ–¹ã«å¯¾å¿œ
    words = re.findall(r'[a-zA-Z]+|[\u3040-\u309f\u30a0-\u30ff\u4e00-\u9fff]+', query)
    return [w.lower() for w in words if len(w) > 1]

def suggest_tools(keywords: list[str]) -> list[str]:
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰ãƒ„ãƒ¼ãƒ«æ¨è–¦"""
    tools = set()
    for kw in keywords:
        for pattern, tool_list in KEYWORD_TO_TOOLS.items():
            if pattern in kw or kw in pattern:
                tools.update(tool_list)
    return list(tools)[:5]

def suggest_skills(keywords: list[str]) -> list[str]:
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰ã‚¹ã‚­ãƒ«æ¨è–¦"""
    skills = set()
    for kw in keywords:
        for pattern, skill_list in KEYWORD_TO_SKILLS.items():
            if pattern in kw or kw in pattern:
                skills.update(skill_list)
    return list(skills)[:3]

def get_search_strategy(query_type: QueryType, keywords: list[str]) -> str:
    """æ¤œç´¢æˆ¦ç•¥ã‚’æ±ºå®š"""
    if query_type == QueryType.ACADEMIC:
        return SEARCH_STRATEGIES["academic"]["description"]
    elif query_type == QueryType.CODE or "ã‚³ãƒ¼ãƒ‰" in keywords:
        return SEARCH_STRATEGIES["code"]["description"]
    elif query_type == QueryType.DATA or "ä¼æ¥­" in keywords:
        return SEARCH_STRATEGIES["company"]["description"]
    elif "ãƒ‹ãƒ¥ãƒ¼ã‚¹" in keywords or "æœ€æ–°" in keywords:
        return SEARCH_STRATEGIES["news"]["description"]
    elif query_type == QueryType.LIBRARY:
        return "ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæ¤œç´¢: PyPI/npm API â†’ GitHub Stars â†’ Context7"
    elif query_type == QueryType.MCP_TOOL:
        return "MCPãƒ„ãƒ¼ãƒ«æ¤œç´¢: mcp_tool_scanner.py â†’ ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿"
    else:
        return SEARCH_STRATEGIES["general"]["description"]

def analyze_query(query: str) -> QueryAnalysis:
    """ã‚¯ã‚¨ãƒªã‚’åˆ†æ"""
    query_type = classify_query(query)
    keywords = extract_keywords(query)
    
    return QueryAnalysis(
        original=query,
        type=query_type,
        keywords=keywords,
        suggested_tools=suggest_tools(keywords),
        suggested_skills=suggest_skills(keywords),
        search_strategy=get_search_strategy(query_type, keywords),
        confidence=0.8 if query_type != QueryType.WEB_SEARCH else 0.5
    )

# ============================================================
# Output Formatters
# ============================================================

def format_analysis(analysis: QueryAnalysis, format: str = "detailed") -> str:
    """åˆ†æçµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    if format == "json":
        return json.dumps({
            "original": analysis.original,
            "type": analysis.type.value,
            "keywords": analysis.keywords,
            "suggested_tools": analysis.suggested_tools,
            "suggested_skills": analysis.suggested_skills,
            "search_strategy": analysis.search_strategy,
            "confidence": analysis.confidence
        }, indent=2, ensure_ascii=False)
    
    output = [
        f"\n{'='*60}",
        f"Query Analysis: {analysis.original}",
        f"{'='*60}",
        f"\nğŸ“‹ Type: {analysis.type.value.upper()}",
        f"ğŸ¯ Confidence: {analysis.confidence:.0%}",
        f"\nğŸ”‘ Keywords: {', '.join(analysis.keywords)}",
        f"\nğŸ”§ Suggested Tools:",
    ]
    for tool in analysis.suggested_tools:
        output.append(f"   â€¢ {tool}")
    
    if analysis.suggested_skills:
        output.append(f"\nğŸ“š Suggested Skills:")
        for skill in analysis.suggested_skills:
            output.append(f"   â€¢ {skill}")
    
    output.append(f"\nğŸ” Search Strategy:")
    output.append(f"   {analysis.search_strategy}")
    
    return "\n".join(output)

def main():
    parser = argparse.ArgumentParser(description="Search Router")
    parser.add_argument("--query", "-q", required=True, help="Query to analyze")
    parser.add_argument("--format", choices=["detailed", "json", "brief"], default="detailed")
    parser.add_argument("--mode", choices=["auto", "research", "code", "data"], default="auto")
    
    args = parser.parse_args()
    
    analysis = analyze_query(args.query)
    print(format_analysis(analysis, args.format))

if __name__ == "__main__":
    main()
