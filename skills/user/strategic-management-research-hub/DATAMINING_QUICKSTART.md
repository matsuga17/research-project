# Strategic Management Research Hub - Data Mining Quick Start Guide

**Version**: 3.1  
**Date**: 2025-11-01  
**Author**: Strategic Management Research Hub

---

## ğŸ“– ç›®æ¬¡

1. [æ¦‚è¦](#æ¦‚è¦)
2. [ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«](#ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«)
3. [5åˆ†ã§å§‹ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ‹ãƒ³ã‚°](#5åˆ†ã§å§‹ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ‹ãƒ³ã‚°)
4. [åŸºæœ¬çš„ãªä½¿ã„æ–¹](#åŸºæœ¬çš„ãªä½¿ã„æ–¹)
5. [é«˜åº¦ãªä½¿ã„æ–¹](#é«˜åº¦ãªä½¿ã„æ–¹)
6. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)
7. [FAQ](#faq)

---

## æ¦‚è¦

æœ¬æ ¼çš„ãªãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ‹ãƒ³ã‚°åˆ†æã‚’**ã‚³ãƒãƒ³ãƒ‰1ã¤**ã§å®Ÿè¡Œã§ãã‚‹çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€‚

### ğŸ¯ ä¸»è¦æ©Ÿèƒ½

1. **æˆ¦ç•¥çš„ã‚°ãƒ«ãƒ¼ãƒ—åˆ†æ** - Porter (1980) ã®ç†è«–ã«åŸºã¥ãä¼æ¥­ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
2. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬** - Random Forest, XGBoost, LightGBM ã«ã‚ˆã‚‹æ¥­ç¸¾äºˆæ¸¬
3. **ç‰¹å¾´é‡é‡è¦åº¦** - SHAP, Permutation Importance ã«ã‚ˆã‚‹å¤‰æ•°é‡è¦åº¦åˆ†æ
4. **ç•°å¸¸æ¤œçŸ¥** - Isolation Forest ã«ã‚ˆã‚‹æˆ¦ç•¥çš„ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ã‚¢ã®ç‰¹å®š
5. **å› æœæ¨è«–** - Double Machine Learning ã«ã‚ˆã‚‹å› æœåŠ¹æœæ¨å®š
6. **æ™‚ç³»åˆ—åˆ†æ** - æˆ¦ç•¥çš„å¤‰æ•°ã®æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³ç™ºè¦‹
7. **çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ** - Publication-Ready ãªHTMLãƒ¬ãƒãƒ¼ãƒˆè‡ªå‹•ç”Ÿæˆ
8. **LaTeXè¡¨å‡ºåŠ›** - è«–æ–‡æŠ•ç¨¿ç”¨ã®è¡¨ã‚’è‡ªå‹•ç”Ÿæˆ

---

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

### ã‚¹ãƒ†ãƒƒãƒ—1: Pythonç’°å¢ƒã®æº–å‚™

```bash
# Python 3.9ä»¥ä¸Šã‚’æ¨å¥¨
python --version

# ä»®æƒ³ç’°å¢ƒã®ä½œæˆï¼ˆæ¨å¥¨ï¼‰
python -m venv datamining_env

# ä»®æƒ³ç’°å¢ƒã®æœ‰åŠ¹åŒ–
# macOS/Linux:
source datamining_env/bin/activate
# Windows:
datamining_env\Scripts\activate
```

### ã‚¹ãƒ†ãƒƒãƒ—2: å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

#### ğŸš€ æœ€å°ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆ5åˆ†ï¼‰

```bash
pip install pandas numpy scikit-learn statsmodels matplotlib seaborn
```

ã“ã‚Œã§ä»¥ä¸‹ãŒä½¿ç”¨å¯èƒ½ï¼š
- æˆ¦ç•¥çš„ã‚°ãƒ«ãƒ¼ãƒ—åˆ†æ
- åŸºæœ¬çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬
- ç•°å¸¸æ¤œçŸ¥

#### ğŸ”¥ æ¨å¥¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆ10åˆ†ï¼‰- å®Œå…¨æ©Ÿèƒ½

```bash
cd /Users/changu/Desktop/ç ”ç©¶/skills/user/strategic-management-research-hub
pip install -r requirements_datamining.txt
```

ã“ã‚Œã§ä»¥ä¸‹ãŒè¿½åŠ ã§ä½¿ç”¨å¯èƒ½ï¼š
- XGBoost, LightGBMï¼ˆé«˜åº¦ãªMLï¼‰
- SHAPï¼ˆèª¬æ˜å¯èƒ½AIï¼‰
- EconMLï¼ˆå› æœæ¨è«–ï¼‰
- UMAPï¼ˆé«˜åº¦ãªå¯è¦–åŒ–ï¼‰

### ã‚¹ãƒ†ãƒƒãƒ—3: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª

```bash
python -c "import pandas, sklearn, matplotlib; print('âœ… ã‚³ã‚¢ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸OK')"

# ãƒ•ãƒ«æ©Ÿèƒ½ã®ç¢ºèª
python -c "import xgboost, shap, econml; print('âœ… å…¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸OK')"
```

---

## 5åˆ†ã§å§‹ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ‹ãƒ³ã‚°

### ğŸš€ æœ€é€Ÿå®Ÿè¡Œï¼ˆ1ã‚³ãƒãƒ³ãƒ‰ï¼‰

```python
from scripts.comprehensive_datamining_pipeline import ComprehensiveDataMiningPipeline

# 1. ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–
pipeline = ComprehensiveDataMiningPipeline(
    data_path='./data/final/analysis_panel.dta',
    output_dir='./my_first_analysis/'
)

# 2. å…¨è‡ªå‹•å®Ÿè¡Œ
results = pipeline.run_complete_analysis()

# 3. çµæœã®ç¢ºèª
print(f"âœ… å®Œäº†ï¼ãƒ¬ãƒãƒ¼ãƒˆ: {pipeline.output_dir / 'comprehensive_report_*.html'}")
```

**ã“ã‚Œã ã‘ã§ä»¥ä¸‹ãŒå®Ÿè¡Œã•ã‚Œã¾ã™**ï¼š
- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼†æ¤œè¨¼
- 8ç¨®é¡ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ‹ãƒ³ã‚°åˆ†æ
- 30ç¨®é¡ä»¥ä¸Šã®ã‚°ãƒ©ãƒ•ç”Ÿæˆ
- HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
- LaTeXè¡¨å‡ºåŠ›

### ğŸ“Š å®Ÿè¡Œæ™‚é–“ã®ç›®å®‰

| ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º | å®Ÿè¡Œæ™‚é–“ | RAMä½¿ç”¨é‡ |
|-------------|---------|----------|
| ~1,000è¦³æ¸¬   | 2-5åˆ†    | < 1GB    |
| ~10,000è¦³æ¸¬  | 10-20åˆ†  | 2-4GB    |
| ~100,000è¦³æ¸¬ | 30-60åˆ†  | 8-16GB   |

---

## åŸºæœ¬çš„ãªä½¿ã„æ–¹

### ğŸ“ ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™

**å¿…é ˆå¤‰æ•°**ï¼š
- `gvkey` (ä¼æ¥­ID) â€»å¤‰æ•°åã¯å¤‰æ›´å¯èƒ½
- `year` (å¹´æ¬¡) â€»å¤‰æ•°åã¯å¤‰æ›´å¯èƒ½

**æ¨å¥¨å¤‰æ•°**ï¼š
- `roa` ã¾ãŸã¯ `roe` (ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™)
- `rd_intensity` (R&Dé›†ç´„åº¦)
- `capital_intensity` (è³‡æœ¬é›†ç´„åº¦)
- `firm_size` (ä¼æ¥­è¦æ¨¡)
- `leverage` (è²¡å‹™ãƒ¬ãƒãƒ¬ãƒƒã‚¸)

**ãƒ‡ãƒ¼ã‚¿å½¢å¼**ï¼š
- Stata (.dta)
- CSV (.csv)
- Parquet (.parquet)

### ğŸ›ï¸ ã‚¹ãƒ†ãƒƒãƒ—2: è¨­å®šã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

```python
from scripts.comprehensive_datamining_pipeline import DataMiningConfig

# ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã®ä½œæˆ
config = DataMiningConfig(
    data_path='./data/final/my_data.dta',
    output_dir='./custom_analysis/',
    
    # æˆ¦ç•¥çš„ç‰¹å¾´é‡ã®æŒ‡å®š
    strategic_features=[
        'rd_intensity',
        'patent_intensity',
        'organizational_slack'
    ],
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
    performance_target='tobin_q',
    
    # ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã®å›ºå®šï¼ˆè‡ªå‹•æ±ºå®šã®å ´åˆã¯Noneï¼‰
    n_clusters=4,
    
    # ä½¿ç”¨ã™ã‚‹MLãƒ¢ãƒ‡ãƒ«
    prediction_models=['rf', 'xgboost', 'ensemble'],
    
    # è¨ˆç®—è¨­å®š
    random_seed=42,
    n_jobs=-1  # å…¨ã‚³ã‚¢ä½¿ç”¨
)

# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
pipeline = ComprehensiveDataMiningPipeline(config=config)
results = pipeline.run_complete_analysis()
```

### ğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—3: çµæœã®ç¢ºèª

```python
# ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼
print(results['data_summary'])

# æˆ¦ç•¥çš„ã‚°ãƒ«ãƒ¼ãƒ—
print(f"ã‚¯ãƒ©ã‚¹ã‚¿æ•°: {results['strategic_groups']['n_clusters']}")
print(results['strategic_groups']['cluster_profiles'])

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬
best_model = results['performance_prediction']['best_model']
best_r2 = results['performance_prediction']['model_results'][best_model]['test_r2']
print(f"æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {best_model} (RÂ² = {best_r2:.4f})")

# ç‰¹å¾´é‡é‡è¦åº¦
print("Top 5 é‡è¦ç‰¹å¾´é‡:")
print(results['feature_importance']['importance_df'].head())
```

---

## é«˜åº¦ãªä½¿ã„æ–¹

### ğŸ”¬ æ®µéšçš„å®Ÿè¡Œï¼ˆç´°ã‹ã„åˆ¶å¾¡ï¼‰

```python
pipeline = ComprehensiveDataMiningPipeline(
    data_path='./data/final/analysis_panel.dta'
)

# Phase 1: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
pipeline.load_and_validate_data()

# Phase 2: æˆ¦ç•¥çš„ã‚°ãƒ«ãƒ¼ãƒ—åˆ†æã®ã¿
sg_results = pipeline.run_strategic_group_analysis(
    features=['rd_intensity', 'capital_intensity', 'international_sales'],
    n_clusters=4,
    method='kmeans'
)

# Phase 3: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬ã®ã¿
pred_results = pipeline.run_performance_prediction(
    target='roa',
    features=['rd_intensity', 'firm_size', 'leverage'],
    models=['rf', 'xgboost']
)

# Phase 4: ç‰¹å¾´é‡é‡è¦åº¦ã®ã¿
fi_results = pipeline.run_feature_importance_analysis()

# Phase 5: ç•°å¸¸æ¤œçŸ¥ã®ã¿
anomaly_results = pipeline.run_anomaly_detection(
    features=['rd_intensity', 'capital_intensity'],
    contamination=0.05
)

# Phase 8: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
report_path = pipeline.generate_comprehensive_report()
```

### ğŸ”¥ å› æœæ¨è«–ï¼ˆDouble Machine Learningï¼‰

```python
config = DataMiningConfig(
    data_path='./data/final/analysis_panel.dta',
    
    # å› æœæ¨è«–ã®è¨­å®š
    treatment_var='rd_intensity',  # å‡¦ç½®: R&DæŠ•è³‡
    outcome_var='roa_lead1',       # çµæœ: ç¿Œå¹´ã®ROA
    causal_method='dml',
    
    control_variables=[
        'firm_size', 'firm_age', 'leverage',
        'industry_concentration'
    ]
)

pipeline = ComprehensiveDataMiningPipeline(config=config)
pipeline.load_and_validate_data()

# å› æœæ¨è«–å®Ÿè¡Œ
causal_results = pipeline.run_causal_inference()

print(f"å¹³å‡å‡¦ç½®åŠ¹æœ (ATE): {causal_results['ate']:.4f}")
print(f"95% CI: {causal_results['ate_ci']}")
print(f"På€¤: {causal_results['p_value']:.4f}")
```

### ğŸ¨ ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³•ã®æ¯”è¼ƒ

```python
methods = ['kmeans', 'hierarchical', 'dbscan']

for method in methods:
    results = pipeline.run_strategic_group_analysis(
        features=['rd_intensity', 'capital_intensity'],
        method=method
    )
    
    print(f"{method}: ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢ = {results['silhouette_score']:.4f}")
```

### ğŸ“ˆ è¤‡æ•°ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã®äºˆæ¸¬

```python
targets = ['roa', 'roe', 'tobin_q', 'sales_growth']

for target in targets:
    results = pipeline.run_performance_prediction(
        target=target,
        features=['rd_intensity', 'firm_size', 'leverage']
    )
    
    best_r2 = results['model_results'][results['best_model']]['test_r2']
    print(f"{target}: RÂ² = {best_r2:.4f}")
```

---

## è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä½¿ç”¨

### YAMLãƒ•ã‚¡ã‚¤ãƒ«ã§ã®è¨­å®šç®¡ç†

```bash
# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ”ãƒ¼
cp configs/datamining_full_config.yaml configs/my_config.yaml

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†
nano configs/my_config.yaml
```

```yaml
# configs/my_config.yaml

data_path: "./data/final/my_panel.dta"
output_dir: "./my_output/"

strategic_features:
  - "rd_intensity"
  - "capital_intensity"
  - "advertising_intensity"

performance_target: "roa"
n_clusters: null  # è‡ªå‹•æ±ºå®š
prediction_models: ["rf", "xgboost", "lightgbm"]
```

```python
# YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å®Ÿè¡Œ
from scripts.comprehensive_datamining_pipeline import ComprehensiveDataMiningPipeline

pipeline = ComprehensiveDataMiningPipeline(
    config_path='./configs/my_config.yaml'
)

results = pipeline.run_complete_analysis()
```

---

## å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«

### ğŸ“‚ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

```
output_dir/
â”œâ”€â”€ comprehensive_report_YYYYMMDD_HHMMSS.html  # çµ±åˆHTMLãƒ¬ãƒãƒ¼ãƒˆ
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ strategic_groups.png                    # æˆ¦ç•¥çš„ã‚°ãƒ«ãƒ¼ãƒ—ã®å¯è¦–åŒ–
â”‚   â”œâ”€â”€ feature_importance.png                  # ç‰¹å¾´é‡é‡è¦åº¦
â”‚   â”œâ”€â”€ anomaly_detection.png                   # ç•°å¸¸æ¤œçŸ¥
â”‚   â””â”€â”€ temporal_patterns.png                   # æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³
â”œâ”€â”€ tables/
â”‚   â”œâ”€â”€ strategic_groups_profiles.tex           # LaTeXè¡¨
â”‚   â””â”€â”€ model_comparison.tex                    # ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒè¡¨
â”œâ”€â”€ models/
â”‚   â””â”€â”€ strategic_groups_model.pkl              # ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«
â””â”€â”€ logs/
    â””â”€â”€ pipeline_YYYYMMDD_HHMMSS.log            # å®Ÿè¡Œãƒ­ã‚°
```

### ğŸ“Š HTMLãƒ¬ãƒãƒ¼ãƒˆã®å†…å®¹

1. **ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼** - è¦³æ¸¬æ•°ã€ä¼æ¥­æ•°ã€åˆ†ææœŸé–“
2. **æˆ¦ç•¥çš„ã‚°ãƒ«ãƒ¼ãƒ—åˆ†æ** - ã‚¯ãƒ©ã‚¹ã‚¿ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã€å¯è¦–åŒ–
3. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬** - ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã€äºˆæ¸¬ç²¾åº¦
4. **ç‰¹å¾´é‡é‡è¦åº¦** - é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€å¯è¦–åŒ–
5. **ç•°å¸¸æ¤œçŸ¥** - ç•°å¸¸å€¤ã®ç‰¹å®šã€å¯è¦–åŒ–
6. **å®Ÿè¡Œæ™‚é–“** - å„ãƒ•ã‚§ãƒ¼ã‚ºã®æ‰€è¦æ™‚é–“

---

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### âŒ ã‚¨ãƒ©ãƒ¼: ModuleNotFoundError

```bash
# ä¸è¶³ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install pandas numpy scikit-learn

# ã¾ãŸã¯
pip install -r requirements_datamining.txt
```

### âŒ ã‚¨ãƒ©ãƒ¼: FileNotFoundError

```python
# ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã®ç¢ºèª
from pathlib import Path

data_path = './data/final/analysis_panel.dta'
print(f"ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨: {Path(data_path).exists()}")
```

### âŒ ã‚¨ãƒ©ãƒ¼: KeyError (å¤‰æ•°ãŒè¦‹ã¤ã‹ã‚‰ãªã„)

```python
# ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ•°ã‚’ç¢ºèª
import pandas as pd
df = pd.read_stata('./data/final/analysis_panel.dta')
print(df.columns.tolist())

# å¤‰æ•°åã‚’è¨­å®šã§å¤‰æ›´
config = DataMiningConfig(
    data_path='./data/final/analysis_panel.dta',
    firm_id='company_id',  # gvkey â†’ company_id
    time_var='fiscal_year'  # year â†’ fiscal_year
)
```

### âŒ ã‚¨ãƒ©ãƒ¼: MemoryError (ãƒ¡ãƒ¢ãƒªä¸è¶³)

```python
# ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã‚’å‰Šæ¸›
import pandas as pd
df = pd.read_stata('./data/final/analysis_panel.dta')
df_sample = df.sample(n=5000, random_state=42)
df_sample.to_csv('./data/final/sample.csv', index=False)

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§å®Ÿè¡Œ
pipeline = ComprehensiveDataMiningPipeline(
    data_path='./data/final/sample.csv'
)
```

### âŒ è­¦å‘Š: EconML not installed

```bash
# å› æœæ¨è«–ã‚’ä½¿ç”¨ã—ãªã„å ´åˆã¯ç„¡è¦–ã—ã¦OK
# ä½¿ç”¨ã™ã‚‹å ´åˆã¯ä»¥ä¸‹ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install econml

# ã¾ãŸã¯condaçµŒç”±
conda install -c conda-forge econml
```

---

## FAQ

### Q1: ã©ã®ãã‚‰ã„ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã¾ã§å¯¾å¿œï¼Ÿ

**A**: æ¨å¥¨ã¯100,000è¦³æ¸¬ã¾ã§ã€‚ãã‚Œä»¥ä¸Šã¯ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¾ãŸã¯Daskã®ä½¿ç”¨ã‚’æ¨å¥¨ã€‚

### Q2: Jupyter Notebookã§ä½¿ç”¨ã§ãã‚‹ï¼Ÿ

**A**: ã¯ã„ã€å®Œå…¨å¯¾å¿œã€‚

```python
# Jupyter Notebookã§ã®ä½¿ç”¨ä¾‹
from scripts.comprehensive_datamining_pipeline import ComprehensiveDataMiningPipeline

pipeline = ComprehensiveDataMiningPipeline(
    data_path='./data/final/analysis_panel.dta',
    output_dir='./notebook_output/'
)

results = pipeline.run_complete_analysis()
```

### Q3: æ—¢å­˜ã®Stata/Rã‚³ãƒ¼ãƒ‰ã¨çµ±åˆã§ãã‚‹ï¼Ÿ

**A**: ã¯ã„ã€å¯èƒ½ã§ã™ã€‚

```python
# Stataãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
import pandas as pd
df = pd.read_stata('./data/final/stata_output.dta')

# Pythonåˆ†æå®Ÿè¡Œ
pipeline = ComprehensiveDataMiningPipeline(...)
results = pipeline.run_complete_analysis()

# çµæœã‚’Stataå½¢å¼ã§ä¿å­˜
results_df = pipeline.data_cleaned
results_df.to_stata('./data/final/python_output.dta')
```

### Q4: è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä¸€åº¦ã«å‡¦ç†ã§ãã‚‹ï¼Ÿ

**A**: ã¯ã„ã€ãƒãƒƒãƒå‡¦ç†ãŒå¯èƒ½ã§ã™ã€‚

```python
datasets = [
    './data/final/manufacturing.dta',
    './data/final/services.dta',
    './data/final/tech.dta'
]

for data_path in datasets:
    pipeline = ComprehensiveDataMiningPipeline(
        data_path=data_path,
        output_dir=f'./batch_output/{Path(data_path).stem}/'
    )
    pipeline.run_complete_analysis()
```

### Q5: çµæœã‚’è«–æ–‡ã«ä½¿ç”¨ã§ãã‚‹å“è³ªï¼Ÿ

**A**: ã¯ã„ã€Publication-Ready ã§ã™ã€‚

- LaTeXè¡¨ã®è‡ªå‹•ç”Ÿæˆ
- é«˜è§£åƒåº¦å›³ï¼ˆ300 DPIï¼‰
- APA/MLAå½¢å¼ã®å¼•ç”¨æƒ…å ±
- å®Œå…¨ãªå†ç¾æ€§ï¼ˆä¹±æ•°ã‚·ãƒ¼ãƒ‰å›ºå®šï¼‰
- è©³ç´°ãªå®Ÿè¡Œãƒ­ã‚°

### Q6: ã‚¯ãƒ©ã‚¦ãƒ‰ï¼ˆAWS, GCPï¼‰ã§å®Ÿè¡Œã§ãã‚‹ï¼Ÿ

**A**: ã¯ã„ã€å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚

```bash
# Dockerã‚³ãƒ³ãƒ†ãƒŠã§ã®å®Ÿè¡Œ
docker run -v $(pwd)/data:/data \
           -v $(pwd)/output:/output \
           python:3.11 \
           python scripts/comprehensive_datamining_pipeline.py \
           --data /data/analysis_panel.dta \
           --output /output/
```

---

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **å®Ÿè¡Œä¾‹ã‚’è©¦ã™**
   ```bash
   python scripts/datamining_quickstart_examples.py
   ```

2. **è©³ç´°ã‚¬ã‚¤ãƒ‰ã‚’èª­ã‚€**
   - [DATAMINING_GUIDE.md](./DATAMINING_GUIDE.md) - å…¨æ‰‹æ³•ã®è©³ç´°è§£èª¬
   - [SKILL.md](./SKILL.md) - ç ”ç©¶ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å…¨ä½“

3. **ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã™ã‚‹**
   - `configs/datamining_full_config.yaml` ã‚’ç·¨é›†
   - ç‹¬è‡ªã®æˆ¦ç•¥çš„ç‰¹å¾´é‡ã‚’è¿½åŠ 
   - å› æœæ¨è«–ã®è¨­å®šã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

4. **ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å‚åŠ **
   - Issueå ±å‘Šãƒ»æ©Ÿèƒ½è¦æœ›: GitHub Issues
   - è³ªå•ãƒ»ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³: GitHub Discussions

---

## å¼•ç”¨

ã“ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ãŸç ”ç©¶ã‚’å…¬é–‹ã™ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã®å½¢å¼ã§ã®å¼•ç”¨ã‚’æ¨å¥¨ã—ã¾ã™ï¼š

**APAå½¢å¼**:
```
Strategic Management Research Hub. (2025). Comprehensive Data Mining Pipeline 
for Strategic Management Research (Version 3.1) [Computer software]. 
https://github.com/your-org/strategic-management-research-hub
```

**BibTeX**:
```bibtex
@software{strategic_datamining_2025,
  author = {{Strategic Management Research Hub}},
  title = {Comprehensive Data Mining Pipeline for Strategic Management Research},
  version = {3.1},
  year = {2025},
  url = {https://github.com/your-org/strategic-management-research-hub}
}
```

---

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT License - å­¦è¡“ç ”ç©¶ãƒ»å•†ç”¨åˆ©ç”¨ã¨ã‚‚ã«è‡ªç”±ã«ä½¿ç”¨å¯èƒ½

---

## ã‚µãƒãƒ¼ãƒˆ

- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: [DATAMINING_GUIDE.md](./DATAMINING_GUIDE.md)
- **ä¾‹**: [scripts/datamining_quickstart_examples.py](./scripts/datamining_quickstart_examples.py)
- **ãƒ†ã‚¹ãƒˆ**: [tests/test_datamining_pipeline.py](./tests/test_datamining_pipeline.py)

---

**Strategic Management Research Hub v3.1**  
*Empowering Strategic Management Research with Advanced Data Mining*
