#!/usr/bin/env python3
"""
Causal Inference Explorer for Strategic & Organizational Research

å› æœæ¨è«–ã®å“²å­¦çš„ãƒ»æ–¹æ³•è«–çš„åŸºç›¤ã«åŸºã¥ãæ¢ç´¢çš„åˆ†æã‚·ã‚¹ãƒ†ãƒ ã€‚
Pearl (2009)ã®å› æœéšå±¤ã€Rubin (1974)ã®æ½œåœ¨çµæœæ çµ„ã¿ã€
ãã—ã¦æº–å®Ÿé¨“çš„ãƒ‡ã‚¶ã‚¤ãƒ³ã®ç¾ä»£çš„æ‰‹æ³•ã‚’çµ±åˆã™ã‚‹ã€‚

Epistemological Foundation:
ç›¸é–¢ã¯å› æœã‚’æ„å‘³ã—ãªã„ã€‚ã—ã‹ã—ã€é©åˆ‡ãªæ–¹æ³•è«–ã¨ç†è«–çš„æ´å¯Ÿã«ã‚ˆã‚Šã€
è¦³å¯Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å› æœçš„æ´å¯Ÿã‚’æŠ½å‡ºã™ã‚‹ã“ã¨ã¯å¯èƒ½ã§ã‚ã‚‹ã€‚
æœ¬ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€ã“ã®çŸ¥çš„å†’é™ºã¸ã®é“ç­‹ã‚’æä¾›ã™ã‚‹ã€‚

Usage:
    python causal_explorer.py <data_file> \\
        --treatment "innovation_investment" \\
        --outcome "firm_performance" \\
        --controls "firm_size,industry_dummies" \\
        --methods "ols,iv,psm,did" \\
        -o <output_dir>

Author: Strategic Research Lab
License: MIT
Version: 1.0.0
"""

import pandas as pd
import numpy as np
from scipy import stats
import statsmodels.api as sm
from statsmodels.formula.api import ols
import json
import argparse
import os
import warnings
warnings.filterwarnings('ignore')

try:
    from sklearn.linear_model import LinearRegression
    from sklearn.neighbors import NearestNeighbors
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False


class CausalExplorer:
    """å› æœé–¢ä¿‚ã‚’æ¢ç´¢çš„ã«åˆ†æã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, data_path, treatment_vars, outcome_vars, control_vars=None,
                 methods=None, iv_instruments=None, psm_caliper=0.1, output_dir="./output"):
        """
        Parameters:
        -----------
        data_path : str
            ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        treatment_vars : str or list
            å‡¦ç½®å¤‰æ•°ï¼ˆç‹¬ç«‹å¤‰æ•°ï¼‰
        outcome_vars : str or list
            çµæœå¤‰æ•°ï¼ˆå¾“å±å¤‰æ•°ï¼‰
        control_vars : str or list, optional
            çµ±åˆ¶å¤‰æ•°
        methods : str or list, optional
            åˆ†ææ‰‹æ³• ("ols", "iv", "psm", "did")
        iv_instruments : str or list, optional
            æ“ä½œå¤‰æ•°ï¼ˆIVã«ä½¿ç”¨ï¼‰
        psm_caliper : float
            å‚¾å‘ã‚¹ã‚³ã‚¢ãƒãƒƒãƒãƒ³ã‚°ã®ã‚­ãƒ£ãƒªãƒ‘ãƒ¼å¹…
        output_dir : str
            å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.data_path = data_path
        self.treatment_vars = self._parse_vars(treatment_vars)
        self.outcome_vars = self._parse_vars(outcome_vars)
        self.control_vars = self._parse_vars(control_vars) if control_vars else []
        self.methods = self._parse_vars(methods) if methods else ["ols"]
        self.iv_instruments = self._parse_vars(iv_instruments) if iv_instruments else []
        self.psm_caliper = psm_caliper
        self.output_dir = output_dir
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        self.df = self._load_data()
        
        # çµæœæ ¼ç´
        self.results = {
            "metadata": {
                "treatment_variables": self.treatment_vars,
                "outcome_variables": self.outcome_vars,
                "control_variables": self.control_vars,
                "methods": self.methods,
                "sample_size": len(self.df)
            },
            "ols_results": {},
            "iv_results": {},
            "psm_results": {},
            "did_results": {},
            "endogeneity_tests": {},
            "robustness_checks": {},
            "causal_interpretations": []
        }
    
    def _parse_vars(self, vars_input):
        """å¤‰æ•°ãƒªã‚¹ãƒˆã®ãƒ‘ãƒ¼ã‚¹"""
        if isinstance(vars_input, str):
            return [v.strip() for v in vars_input.split(',')]
        elif isinstance(vars_input, list):
            return vars_input
        else:
            return []
    
    def _load_data(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
        ext = os.path.splitext(self.data_path)[1].lower()
        
        if ext == '.csv':
            return pd.read_csv(self.data_path)
        elif ext in ['.xlsx', '.xls']:
            return pd.read_excel(self.data_path)
        elif ext == '.dta':
            return pd.read_stata(self.data_path)
        elif ext == '.sav':
            return pd.read_spss(self.data_path)
        else:
            raise ValueError(f"Unsupported file format: {ext}")
    
    def perform_ols_analysis(self):
        """OLSå›å¸°åˆ†æï¼šåŸºæœ¬çš„ãªé–¢ä¿‚æ€§ã®æ¢ç´¢"""
        print("ğŸ“Š Performing OLS regression analysis...")
        
        for treatment in self.treatment_vars:
            for outcome in self.outcome_vars:
                if treatment not in self.df.columns or outcome not in self.df.columns:
                    continue
                
                # ãƒ‡ãƒ¼ã‚¿æº–å‚™
                analysis_df = self.df[[treatment, outcome] + self.control_vars].dropna()
                
                if len(analysis_df) < 30:
                    continue
                
                # ãƒ¢ãƒ‡ãƒ«1ï¼šçµ±åˆ¶å¤‰æ•°ãªã—
                X1 = sm.add_constant(analysis_df[treatment])
                y = analysis_df[outcome]
                
                model1 = sm.OLS(y, X1).fit()
                
                # ãƒ¢ãƒ‡ãƒ«2ï¼šçµ±åˆ¶å¤‰æ•°ã‚ã‚Š
                if self.control_vars:
                    X2 = sm.add_constant(analysis_df[[treatment] + self.control_vars])
                    model2 = sm.OLS(y, X2).fit()
                else:
                    model2 = model1
                
                # æ®‹å·®è¨ºæ–­
                residuals = model2.resid
                normality_stat, normality_p = stats.shapiro(residuals) if len(residuals) < 5000 else (np.nan, np.nan)
                
                # Breusch-Paganæ¤œå®šï¼ˆç­‰åˆ†æ•£æ€§ï¼‰
                from statsmodels.stats.diagnostic import het_breuschpagan
                bp_stat, bp_p, _, _ = het_breuschpagan(model2.resid, model2.model.exog)
                
                # çµæœã®æ ¼ç´
                result_key = f"{treatment}_to_{outcome}"
                self.results["ols_results"][result_key] = {
                    "model1_no_controls": {
                        "coefficient": float(model1.params[treatment]),
                        "std_error": float(model1.bse[treatment]),
                        "t_statistic": float(model1.tvalues[treatment]),
                        "p_value": float(model1.pvalues[treatment]),
                        "r_squared": float(model1.rsquared),
                        "adj_r_squared": float(model1.rsquared_adj),
                        "n_obs": int(model1.nobs)
                    },
                    "model2_with_controls": {
                        "coefficient": float(model2.params[treatment]),
                        "std_error": float(model2.bse[treatment]),
                        "t_statistic": float(model2.tvalues[treatment]),
                        "p_value": float(model2.pvalues[treatment]),
                        "r_squared": float(model2.rsquared),
                        "adj_r_squared": float(model2.rsquared_adj),
                        "n_obs": int(model2.nobs),
                        "f_statistic": float(model2.fvalue),
                        "f_pvalue": float(model2.f_pvalue)
                    },
                    "diagnostics": {
                        "residual_normality_pvalue": float(normality_p) if not np.isnan(normality_p) else None,
                        "heteroscedasticity_bp_pvalue": float(bp_p),
                        "durbin_watson": float(sm.stats.stattools.durbin_watson(residuals))
                    },
                    "interpretation": self._interpret_ols(model2, treatment)
                }
    
    def _interpret_ols(self, model, treatment):
        """OLSçµæœã®è§£é‡ˆ"""
        coef = model.params[treatment]
        pval = model.pvalues[treatment]
        
        interpretations = []
        
        # çµ±è¨ˆçš„æœ‰æ„æ€§
        if pval < 0.001:
            interpretations.append(f"Highly significant effect (p < 0.001)")
        elif pval < 0.01:
            interpretations.append(f"Significant effect (p < 0.01)")
        elif pval < 0.05:
            interpretations.append(f"Significant effect (p < 0.05)")
        else:
            interpretations.append(f"No significant effect (p = {pval:.3f})")
        
        # æ–¹å‘æ€§
        if coef > 0:
            interpretations.append("Positive relationship")
        else:
            interpretations.append("Negative relationship")
        
        # æ³¨æ„äº‹é …
        interpretations.append("âš ï¸ Correlation does not imply causation. Consider endogeneity.")
        
        return interpretations
    
    def test_endogeneity(self):
        """å†…ç”Ÿæ€§ã®è¨ºæ–­ï¼šDurbin-Wu-Hausmanæ¤œå®š"""
        print("ğŸ” Testing for endogeneity...")
        
        if not self.iv_instruments or "iv" not in self.methods:
            self.results["endogeneity_tests"]["status"] = "no_instruments_specified"
            return
        
        for treatment in self.treatment_vars:
            for outcome in self.outcome_vars:
                if treatment not in self.df.columns or outcome not in self.df.columns:
                    continue
                
                # ç¬¬1æ®µéšï¼šæ“ä½œå¤‰æ•°ã§å‡¦ç½®å¤‰æ•°ã‚’å›å¸°
                valid_instruments = [iv for iv in self.iv_instruments if iv in self.df.columns]
                if not valid_instruments:
                    continue
                
                analysis_df = self.df[[treatment, outcome] + self.control_vars + valid_instruments].dropna()
                
                if len(analysis_df) < 50:
                    continue
                
                # ç¬¬1æ®µéšã®å›å¸°
                X_stage1 = sm.add_constant(analysis_df[valid_instruments + self.control_vars])
                y_stage1 = analysis_df[treatment]
                
                stage1_model = sm.OLS(y_stage1, X_stage1).fit()
                residuals_stage1 = stage1_model.resid
                
                # å¼±æ“ä½œå¤‰æ•°æ¤œå®šï¼ˆç¬¬1æ®µéšã®Fçµ±è¨ˆé‡ï¼‰
                f_stat_stage1 = stage1_model.fvalue
                
                # ç¬¬2æ®µéšï¼šæ®‹å·®ã‚’å«ã‚ãŸOLS
                X_stage2 = sm.add_constant(analysis_df[[treatment] + self.control_vars])
                X_stage2_with_resid = X_stage2.copy()
                X_stage2_with_resid['stage1_residuals'] = residuals_stage1
                
                y_stage2 = analysis_df[outcome]
                
                stage2_model = sm.OLS(y_stage2, X_stage2_with_resid).fit()
                
                # æ®‹å·®ã®ä¿‚æ•°ã®tæ¤œå®š â†’ å†…ç”Ÿæ€§ã®æ¤œå®š
                resid_coef = stage2_model.params['stage1_residuals']
                resid_pval = stage2_model.pvalues['stage1_residuals']
                
                result_key = f"{treatment}_to_{outcome}"
                self.results["endogeneity_tests"][result_key] = {
                    "instruments_used": valid_instruments,
                    "first_stage_f_statistic": float(f_stat_stage1),
                    "weak_instrument_concern": bool(f_stat_stage1 < 10),
                    "durbin_wu_hausman": {
                        "residual_coefficient": float(resid_coef),
                        "p_value": float(resid_pval),
                        "endogeneity_detected": bool(resid_pval < 0.05)
                    },
                    "interpretation": self._interpret_endogeneity(f_stat_stage1, resid_pval)
                }
    
    def _interpret_endogeneity(self, f_stat, dwh_p):
        """å†…ç”Ÿæ€§æ¤œå®šã®è§£é‡ˆ"""
        interpretations = []
        
        # å¼±æ“ä½œå¤‰æ•°
        if f_stat < 10:
            interpretations.append("âš ï¸ Weak instrument problem (F < 10). IV estimates may be unreliable.")
        else:
            interpretations.append(f"âœ“ Strong instrument (F = {f_stat:.2f})")
        
        # å†…ç”Ÿæ€§
        if dwh_p < 0.05:
            interpretations.append(f"âš ï¸ Endogeneity detected (p = {dwh_p:.4f}). OLS is inconsistent. Use IV/2SLS.")
        else:
            interpretations.append(f"âœ“ No endogeneity detected (p = {dwh_p:.4f}). OLS is consistent.")
        
        return interpretations
    
    def perform_iv_analysis(self):
        """æ“ä½œå¤‰æ•°æ³•ï¼ˆIV/2SLSï¼‰ã«ã‚ˆã‚‹å› æœæ¨è«–"""
        print("ğŸ¯ Performing Instrumental Variables analysis...")
        
        if "iv" not in self.methods or not self.iv_instruments:
            return
        
        for treatment in self.treatment_vars:
            for outcome in self.outcome_vars:
                if treatment not in self.df.columns or outcome not in self.df.columns:
                    continue
                
                valid_instruments = [iv for iv in self.iv_instruments if iv in self.df.columns]
                if not valid_instruments:
                    continue
                
                analysis_df = self.df[[treatment, outcome] + self.control_vars + valid_instruments].dropna()
                
                if len(analysis_df) < 50:
                    continue
                
                # ç¬¬1æ®µéšï¼šæ“ä½œå¤‰æ•°ã§å‡¦ç½®å¤‰æ•°ã‚’å›å¸°
                X_stage1 = sm.add_constant(analysis_df[valid_instruments + self.control_vars])
                y_stage1 = analysis_df[treatment]
                
                stage1_model = sm.OLS(y_stage1, X_stage1).fit()
                treatment_hat = stage1_model.predict(X_stage1)
                
                # ç¬¬2æ®µéšï¼šäºˆæ¸¬ã•ã‚ŒãŸå‡¦ç½®å¤‰æ•°ã§çµæœå¤‰æ•°ã‚’å›å¸°
                X_stage2 = sm.add_constant(pd.DataFrame({
                    treatment: treatment_hat,
                    **{col: analysis_df[col] for col in self.control_vars}
                }))
                y_stage2 = analysis_df[outcome]
                
                stage2_model = sm.OLS(y_stage2, X_stage2).fit()
                
                # æ¨™æº–èª¤å·®ã®èª¿æ•´ï¼ˆ2SLSç”¨ï¼‰
                # æ³¨ï¼šæ­£ç¢ºãª2SLSã«ã¯linearmodelsãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æ¨å¥¨
                
                result_key = f"{treatment}_to_{outcome}"
                self.results["iv_results"][result_key] = {
                    "first_stage": {
                        "f_statistic": float(stage1_model.fvalue),
                        "r_squared": float(stage1_model.rsquared),
                        "instrument_strength": "strong" if stage1_model.fvalue > 10 else "weak"
                    },
                    "second_stage": {
                        "coefficient": float(stage2_model.params[treatment]),
                        "std_error": float(stage2_model.bse[treatment]),
                        "t_statistic": float(stage2_model.tvalues[treatment]),
                        "p_value": float(stage2_model.pvalues[treatment])
                    },
                    "interpretation": self._interpret_iv(stage1_model, stage2_model, treatment)
                }
    
    def _interpret_iv(self, stage1_model, stage2_model, treatment):
        """IVæ¨å®šã®è§£é‡ˆ"""
        interpretations = []
        
        f_stat = stage1_model.fvalue
        coef = stage2_model.params[treatment]
        pval = stage2_model.pvalues[treatment]
        
        # ç¬¬1æ®µéš
        if f_stat < 10:
            interpretations.append("âš ï¸ Weak instrument: IV estimates may be biased")
        else:
            interpretations.append(f"âœ“ Strong instrument (F = {f_stat:.2f})")
        
        # ç¬¬2æ®µéš
        if pval < 0.05:
            direction = "positive" if coef > 0 else "negative"
            interpretations.append(f"Significant {direction} causal effect (p = {pval:.4f})")
            interpretations.append(f"LATE (Local Average Treatment Effect) = {coef:.4f}")
        else:
            interpretations.append(f"No significant causal effect (p = {pval:.4f})")
        
        interpretations.append("Note: IV estimates represent local average treatment effect (LATE)")
        
        return interpretations
    
    def perform_psm_analysis(self):
        """å‚¾å‘ã‚¹ã‚³ã‚¢ãƒãƒƒãƒãƒ³ã‚°ï¼ˆPSMï¼‰ã«ã‚ˆã‚‹å› æœæ¨è«–"""
        print("ğŸ² Performing Propensity Score Matching...")
        
        if "psm" not in self.methods or not SKLEARN_AVAILABLE:
            return
        
        for treatment in self.treatment_vars:
            for outcome in self.outcome_vars:
                if treatment not in self.df.columns or outcome not in self.df.columns:
                    continue
                
                # äºŒå€¤å‡¦ç½®å¤‰æ•°ã®ç¢ºèª
                if self.df[treatment].nunique() > 2:
                    continue
                
                analysis_df = self.df[[treatment, outcome] + self.control_vars].dropna()
                
                if len(analysis_df) < 50:
                    continue
                
                # å‚¾å‘ã‚¹ã‚³ã‚¢ã®æ¨å®šï¼ˆãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼‰
                from sklearn.linear_model import LogisticRegression
                
                X_ps = analysis_df[self.control_vars]
                y_ps = analysis_df[treatment]
                
                ps_model = LogisticRegression(max_iter=1000)
                ps_model.fit(X_ps, y_ps)
                
                propensity_scores = ps_model.predict_proba(X_ps)[:, 1]
                analysis_df['propensity_score'] = propensity_scores
                
                # å‡¦ç½®ç¾¤ã¨å¯¾ç…§ç¾¤
                treated = analysis_df[analysis_df[treatment] == 1]
                control = analysis_df[analysis_df[treatment] == 0]
                
                # ãƒãƒƒãƒãƒ³ã‚°ï¼ˆæœ€è¿‘å‚æ³•ï¼‰
                matches = []
                for idx, row in treated.iterrows():
                    ps_treated = row['propensity_score']
                    
                    # ã‚­ãƒ£ãƒªãƒ‘ãƒ¼å†…ã®å¯¾ç…§ç¾¤ã‚’æ¤œç´¢
                    candidates = control[
                        (control['propensity_score'] >= ps_treated - self.psm_caliper) &
                        (control['propensity_score'] <= ps_treated + self.psm_caliper)
                    ]
                    
                    if len(candidates) > 0:
                        # æœ€ã‚‚è¿‘ã„å¯¾ç…§ã‚’é¸æŠ
                        distances = np.abs(candidates['propensity_score'] - ps_treated)
                        matched_idx = distances.idxmin()
                        matches.append((idx, matched_idx))
                
                if len(matches) < 10:
                    continue
                
                # ATTï¼ˆAverage Treatment Effect on the Treatedï¼‰ã®è¨ˆç®—
                treated_outcomes = [treated.loc[t_idx, outcome] for t_idx, _ in matches]
                matched_control_outcomes = [control.loc[c_idx, outcome] for _, c_idx in matches]
                
                att = np.mean(treated_outcomes) - np.mean(matched_control_outcomes)
                att_se = np.sqrt(
                    np.var(treated_outcomes) / len(treated_outcomes) +
                    np.var(matched_control_outcomes) / len(matched_control_outcomes)
                )
                att_tstat = att / att_se
                att_pval = 2 * (1 - stats.norm.cdf(abs(att_tstat)))
                
                # ãƒãƒ©ãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
                balance_tests = {}
                for control_var in self.control_vars:
                    treated_mean = treated.loc[[m[0] for m in matches], control_var].mean()
                    control_mean = control.loc[[m[1] for m in matches], control_var].mean()
                    pooled_std = np.sqrt(
                        (treated.loc[[m[0] for m in matches], control_var].var() +
                         control.loc[[m[1] for m in matches], control_var].var()) / 2
                    )
                    std_diff = (treated_mean - control_mean) / pooled_std if pooled_std > 0 else 0
                    
                    balance_tests[control_var] = {
                        "standardized_difference": float(std_diff),
                        "balanced": bool(abs(std_diff) < 0.10)
                    }
                
                result_key = f"{treatment}_to_{outcome}"
                self.results["psm_results"][result_key] = {
                    "n_matches": len(matches),
                    "n_treated": len(treated),
                    "n_control": len(control),
                    "common_support_rate": float(len(matches) / len(treated)),
                    "att": {
                        "estimate": float(att),
                        "std_error": float(att_se),
                        "t_statistic": float(att_tstat),
                        "p_value": float(att_pval)
                    },
                    "balance_tests": balance_tests,
                    "interpretation": self._interpret_psm(att, att_pval, balance_tests, len(matches))
                }
    
    def _interpret_psm(self, att, pval, balance_tests, n_matches):
        """PSMçµæœã®è§£é‡ˆ"""
        interpretations = []
        
        # ãƒãƒƒãƒãƒ³ã‚°å“è³ª
        if n_matches < 20:
            interpretations.append("âš ï¸ Limited matches: Results may be unstable")
        else:
            interpretations.append(f"âœ“ Sufficient matches (n = {n_matches})")
        
        # ãƒãƒ©ãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
        unbalanced = [k for k, v in balance_tests.items() if not v["balanced"]]
        if unbalanced:
            interpretations.append(f"âš ï¸ Covariate imbalance detected: {', '.join(unbalanced)}")
        else:
            interpretations.append("âœ“ Good covariate balance achieved")
        
        # ATT
        if pval < 0.05:
            direction = "positive" if att > 0 else "negative"
            interpretations.append(f"Significant {direction} treatment effect (ATT = {att:.4f}, p = {pval:.4f})")
        else:
            interpretations.append(f"No significant treatment effect (ATT = {att:.4f}, p = {pval:.4f})")
        
        interpretations.append("Note: PSM assumes selection on observables (no unobserved confounders)")
        
        return interpretations
    
    def perform_did_analysis(self):
        """å·®åˆ†ã®å·®åˆ†æ³•ï¼ˆDIDï¼‰ã«ã‚ˆã‚‹å› æœæ¨è«–"""
        print("ğŸ“ˆ Performing Difference-in-Differences analysis...")
        
        if "did" not in self.methods:
            return
        
        # DIDã«ã¯æ™‚é–“å¤‰æ•°ã¨å‡¦ç½®å¤‰æ•°ãŒå¿…è¦
        required_cols = ["time_period", "treatment_group"]
        if not all(col in self.df.columns for col in required_cols):
            self.results["did_results"]["status"] = "missing_required_columns"
            return
        
        for outcome in self.outcome_vars:
            if outcome not in self.df.columns:
                continue
            
            # å‡¦ç½®å‰å¾Œã®ãƒ‡ãƒ¼ã‚¿
            analysis_df = self.df[["time_period", "treatment_group", outcome] + self.control_vars].dropna()
            
            # DIDæ¨å®š
            # Y = Î²â‚€ + Î²â‚*Treat + Î²â‚‚*Post + Î²â‚ƒ*(TreatÃ—Post) + Controls + Îµ
            analysis_df['post'] = (analysis_df['time_period'] > analysis_df['time_period'].median()).astype(int)
            analysis_df['treat_x_post'] = analysis_df['treatment_group'] * analysis_df['post']
            
            X_did = sm.add_constant(analysis_df[['treatment_group', 'post', 'treat_x_post'] + self.control_vars])
            y_did = analysis_df[outcome]
            
            did_model = sm.OLS(y_did, X_did).fit()
            
            # Î²â‚ƒãŒDIDæ¨å®šé‡
            did_estimate = did_model.params['treat_x_post']
            did_se = did_model.bse['treat_x_post']
            did_t = did_model.tvalues['treat_x_post']
            did_p = did_model.pvalues['treat_x_post']
            
            self.results["did_results"][outcome] = {
                "did_estimate": float(did_estimate),
                "std_error": float(did_se),
                "t_statistic": float(did_t),
                "p_value": float(did_p),
                "r_squared": float(did_model.rsquared),
                "interpretation": self._interpret_did(did_estimate, did_p)
            }
    
    def _interpret_did(self, did_est, pval):
        """DIDçµæœã®è§£é‡ˆ"""
        interpretations = []
        
        if pval < 0.05:
            direction = "positive" if did_est > 0 else "negative"
            interpretations.append(f"Significant {direction} treatment effect (DiD = {did_est:.4f}, p = {pval:.4f})")
        else:
            interpretations.append(f"No significant treatment effect (DiD = {did_est:.4f}, p = {pval:.4f})")
        
        interpretations.append("Note: DiD assumes parallel trends between treatment and control groups")
        interpretations.append("Consider: Placebo tests, event study, dynamic effects")
        
        return interpretations
    
    def generate_causal_interpretations(self):
        """å› æœçš„æ´å¯Ÿã®çµ±åˆçš„ç”Ÿæˆ"""
        print("ğŸ’¡ Generating causal interpretations...")
        
        insights = []
        
        # å†…ç”Ÿæ€§ã®è©•ä¾¡
        for key, test_result in self.results.get("endogeneity_tests", {}).items():
            if isinstance(test_result, dict) and "durbin_wu_hausman" in test_result:
                if test_result["durbin_wu_hausman"]["endogeneity_detected"]:
                    insights.append({
                        "type": "endogeneity_warning",
                        "relationship": key,
                        "message": f"Endogeneity detected for {key}. OLS estimates are biased. IV or experimental design recommended.",
                        "severity": "high"
                    })
        
        # æ‰‹æ³•é–“ã®ä¸€è²«æ€§
        for treatment in self.treatment_vars:
            for outcome in self.outcome_vars:
                result_key = f"{treatment}_to_{outcome}"
                
                ols_sig = self.results.get("ols_results", {}).get(result_key, {}).get("model2_with_controls", {}).get("p_value", 1) < 0.05
                iv_sig = self.results.get("iv_results", {}).get(result_key, {}).get("second_stage", {}).get("p_value", 1) < 0.05
                psm_sig = self.results.get("psm_results", {}).get(result_key, {}).get("att", {}).get("p_value", 1) < 0.05
                
                consistency = sum([ols_sig, iv_sig, psm_sig])
                
                if consistency >= 2:
                    insights.append({
                        "type": "consistent_evidence",
                        "relationship": result_key,
                        "message": f"Consistent evidence across multiple methods for {result_key}",
                        "severity": "informative"
                    })
                elif consistency == 1:
                    insights.append({
                        "type": "mixed_evidence",
                        "relationship": result_key,
                        "message": f"Mixed evidence across methods for {result_key}. Interpret with caution.",
                        "severity": "medium"
                    })
        
        self.results["causal_interpretations"] = insights
    
    def run_complete_analysis(self):
        """å®Œå…¨ãªå› æœæ¨è«–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œ"""
        print("ğŸš€ Starting Causal Inference Exploration...")
        
        # åˆ†æã®å®Ÿè¡Œ
        if "ols" in self.methods:
            self.perform_ols_analysis()
        
        self.test_endogeneity()
        
        if "iv" in self.methods:
            self.perform_iv_analysis()
        
        if "psm" in self.methods:
            self.perform_psm_analysis()
        
        if "did" in self.methods:
            self.perform_did_analysis()
        
        self.generate_causal_interpretations()
        
        # çµæœã®ä¿å­˜
        os.makedirs(self.output_dir, exist_ok=True)
        output_path = os.path.join(self.output_dir, "causal_inference_results.json")
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… Causal analysis complete! Results saved to: {output_path}")
        print(f"ğŸ“Š Methods applied: {', '.join(self.methods)}")
        print(f"ğŸ’¡ Insights generated: {len(self.results['causal_interpretations'])}")
        
        return self.results


def main():
    parser = argparse.ArgumentParser(
        description="Causal Inference Explorer for Strategic Research",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument("data_file", help="Path to data file")
    parser.add_argument("--treatment", "--treatment-vars", dest="treatment_vars", required=True,
                       help="Comma-separated treatment variables")
    parser.add_argument("--outcome", "--outcome-vars", dest="outcome_vars", required=True,
                       help="Comma-separated outcome variables")
    parser.add_argument("--controls", "--control-vars", dest="control_vars",
                       help="Comma-separated control variables")
    parser.add_argument("--methods", default="ols",
                       help="Analysis methods: ols,iv,psm,did")
    parser.add_argument("--iv-instruments", dest="iv_instruments",
                       help="Comma-separated instrumental variables")
    parser.add_argument("--psm-caliper", type=float, default=0.1,
                       help="Caliper width for PSM (default: 0.1)")
    parser.add_argument("-o", "--output", default="./output",
                       help="Output directory")
    
    args = parser.parse_args()
    
    # åˆ†æã®å®Ÿè¡Œ
    explorer = CausalExplorer(
        data_path=args.data_file,
        treatment_vars=args.treatment_vars,
        outcome_vars=args.outcome_vars,
        control_vars=args.control_vars,
        methods=args.methods,
        iv_instruments=args.iv_instruments,
        psm_caliper=args.psm_caliper,
        output_dir=args.output
    )
    
    explorer.run_complete_analysis()


if __name__ == "__main__":
    main()
